<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.552">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Gaylen E Fronk">
<meta name="author" content="John J. Curtin">
<meta name="dcterms.date" content="2024-05-13">
<meta name="keywords" content="Substance use disorders, Precision mental health, Cigarette smoking, Machine learning, Treatment selection">

<title>Machine learning-assisted treatment selection for smoking cessation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


<meta name="citation_title" content="Machine learning-assisted treatment selection for smoking cessation">
<meta name="citation_abstract" content="This study found some pretty cool results that have both high impact and important clinical implications.  For example ...
">
<meta name="citation_keywords" content="Substance use disorders,Precision mental health,Cigarette smoking,Machine learning,Treatment selection">
<meta name="citation_author" content="Gaylen E Fronk">
<meta name="citation_author" content="John J. Curtin">
<meta name="citation_publication_date" content="2024-05-13">
<meta name="citation_cover_date" content="2024-05-13">
<meta name="citation_year" content="2024">
<meta name="citation_online_date" content="2024-05-13">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="Journal of Important Findings">
<meta name="citation_reference" content="citation_title=Literate programming;,citation_author=Donald E. Knuth;,citation_publication_date=1984-05;,citation_cover_date=1984-05;,citation_year=1984;,citation_fulltext_html_url=https://doi.org/10.1093/comjnl/27.2.97;,citation_issue=2;,citation_doi=10.1093/comjnl/27.2.97;,citation_issn=0010-4620;,citation_volume=27;,citation_journal_title=Comput. J.;,citation_publisher=Oxford University Press, Inc.;">
</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Machine learning-assisted treatment selection for smoking cessation</h1>
          </div>

    
    <div class="quarto-title-meta-container">
      <div class="quarto-title-meta-column-start">
            <div class="quarto-title-meta-author">
          <div class="quarto-title-meta-heading">Authors</div>
          <div class="quarto-title-meta-heading">Affiliation</div>
          
                <div class="quarto-title-meta-contents">
            <p class="author">Gaylen E Fronk <a href="https://orcid.org/0000-0001-6653-9699" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        Department of Psychology, University of Wisconsin-Madison
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">John J. Curtin <a href="mailto:jjcurtin@wisc.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0002-3286-938X" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        Department of Psychology, University of Wisconsin-Madison
                      </p>
                  </div>
                    </div>
        
        <div class="quarto-title-meta">

                      
                <div>
            <div class="quarto-title-meta-heading">Published</div>
            <div class="quarto-title-meta-contents">
              <p class="date">May 13, 2024</p>
            </div>
          </div>
          
                
              </div>
      </div>
      <div class="quarto-title-meta-column-end quarto-other-formats-target">
      <div class="quarto-alternate-formats"><div class="quarto-title-meta-heading">Other Formats</div><div class="quarto-title-meta-contents"><p><a href="index.docx"><i class="bi bi-file-word"></i>MS Word</a></p></div><div class="quarto-title-meta-contents"><p><a href="index.pdf"><i class="bi bi-file-pdf"></i>Typst (apaish-manuscript)</a></p></div></div></div>
    </div>

    <div>
      <div class="abstract">
        <div class="block-title">Abstract</div>
        <p>This study found some pretty cool results that have both high impact and important clinical implications. For example …</p>
      </div>
    </div>

    <div>
      <div class="keywords">
        <div class="block-title">Keywords</div>
        <p>Substance use disorders, Precision mental health, Cigarette smoking, Machine learning, Treatment selection</p>
      </div>
    </div>

    <div class="quarto-other-links-text-target">
    </div>  </div>
</header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#precision-mental-health" id="toc-precision-mental-health" class="nav-link" data-scroll-target="#precision-mental-health">Precision mental health</a></li>
  <li><a href="#applying-machine-learning-approaches" id="toc-applying-machine-learning-approaches" class="nav-link" data-scroll-target="#applying-machine-learning-approaches">Applying machine learning approaches</a></li>
  <li><a href="#opportunities-to-improve-equity-in-mental-health-treatment" id="toc-opportunities-to-improve-equity-in-mental-health-treatment" class="nav-link" data-scroll-target="#opportunities-to-improve-equity-in-mental-health-treatment">Opportunities to improve equity in mental health treatment</a></li>
  <li><a href="#cigarette-smoking-as-a-critical-precision-mental-health-target" id="toc-cigarette-smoking-as-a-critical-precision-mental-health-target" class="nav-link" data-scroll-target="#cigarette-smoking-as-a-critical-precision-mental-health-target">Cigarette smoking as a critical precision mental health target</a></li>
  <li><a href="#purpose" id="toc-purpose" class="nav-link" data-scroll-target="#purpose">Purpose</a></li>
  </ul></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods">Methods</a>
  <ul class="collapse">
  <li><a href="#transparency-openness" id="toc-transparency-openness" class="nav-link" data-scroll-target="#transparency-openness">Transparency &amp; openness</a></li>
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data">Data</a></li>
  <li><a href="#aim-1-analytic-strategy-model-building" id="toc-aim-1-analytic-strategy-model-building" class="nav-link" data-scroll-target="#aim-1-analytic-strategy-model-building">AIM 1 analytic strategy: Model building</a></li>
  <li><a href="#aim-2-analytic-strategy-evaluation-of-clinical-benefit" id="toc-aim-2-analytic-strategy-evaluation-of-clinical-benefit" class="nav-link" data-scroll-target="#aim-2-analytic-strategy-evaluation-of-clinical-benefit">AIM 2 analytic strategy: Evaluation of clinical benefit</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a>
  <ul class="collapse">
  <li><a href="#sample-characteristics" id="toc-sample-characteristics" class="nav-link" data-scroll-target="#sample-characteristics">Sample characteristics</a></li>
  <li><a href="#model-performance" id="toc-model-performance" class="nav-link" data-scroll-target="#model-performance">Model performance</a></li>
  <li><a href="#feature-importance" id="toc-feature-importance" class="nav-link" data-scroll-target="#feature-importance">Feature importance</a></li>
  <li><a href="#clinical-benefit" id="toc-clinical-benefit" class="nav-link" data-scroll-target="#clinical-benefit">Clinical benefit</a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="quarto-alternate-notebooks"><h2>Notebooks</h2><ul><li><a href="notebooks\ana_bayes_match-preview.html"><i class="bi bi-journal-code"></i>Posterior probabilities across models for MATCH study (version `r params$version`)</a></li><li><a href="notebooks\eval_benefit_4wk-preview.html"><i class="bi bi-journal-code"></i>Evaluation of Clinical Benefit: Week 4 Model</a></li><li><a href="notebooks\fit_final_model_26wk-preview.html"><i class="bi bi-journal-code"></i>Fits and characterizes final model for version `r params$version` for outcome `r params$y_col_name`</a></li><li><a href="notebooks\fit_final_model_4wk-preview.html"><i class="bi bi-journal-code"></i>Fits and characterizes final model for version `r params$version` for outcome `r params$y_col_name`</a></li><li><a href="notebooks\shap_4wk-preview.html"><i class="bi bi-journal-code"></i>SHAP for 4-Week Model</a></li></ul></div></nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">



  


<!-- EDIT EVERYTHING FROM NRSA TO BE PAST TENSE!!! -->
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<!-- 
numbers correspond to nrsa refs
other refs likely missing
-->
<section id="precision-mental-health" class="level3">
<h3 class="anchored" data-anchor-id="precision-mental-health">Precision mental health</h3>
<p>Precision mental health is the application of the precision medicine paradigm to mental health conditions.<!-- need new citation --> Precision medicine and precision mental health aim to address an important problem in traditional treatment selection: what works best at a population level does not necessarily work best for a given patient. For example, although treatment A may be more effective than treatment B across the population, it may be that treatment B is markedly more effective for a specific patient.</p>
<p>Rather than relying on population-level efficacy, precision mental health seeks to guide treatment selection using individual difference characteristics that are likely to predict treatment success for each patient.2 Successful precision mental health would increase the likelihood of treatment success for each patient because each patient receives the treatment predicted to work best for them. It would also improve treatment effectiveness rates across the population because each treatment is administered only to the patients for whom that treatment is expected to be their best option.</p>
<p>In addition to offering improved effectiveness, precision mental health approaches may be more resource-efficient. Clinical trials to develop and validate new treatments are expensive, resource-intensive, and extremely slow (CITE?). These costs may also produce a treatment that is no better than existing treatments, or potentially ineffective altogether. In contrast, by seeking to optimize existing treatments and direct them to the <em>right</em> patients, precision mental health stands as a cost-effective alternative poised for more immediate impact to patients.</p>
<p>Researchers have pursued precision mental health – and precision medicine broadly – for decades. In medicine, emphasis on personalizing treatments has grown rapidly with the ascendancy of advanced genetic methods such as genome-wide association studies and polygenic scores3,4. Within precision mental health, an early example comes from the substance use disorder (SUD) domain: the Project MATCH Research Group attempted to match people with alcohol use disorder to a particular treatment based on individual differences such as gender, social support, or symptom severity5,6. Many researchers have followed in their footsteps as the understanding has grown that neither mental health diagnoses nor treatments are one-size-fits-all7. Efforts thus far have often focused on tailoring treatments at the group level; in other words, identifying a (single) factor that divides individuals within a diagnostic category into subgroups that can be treated differently7. <!-- consider more citations/references to how much this approach has taken off across mental health conditions. not sure if it makes sense here as a more general discussion or to be more specific later with sud/smoking (currently have it there, but could add non-sud/smoking examples here eg cancer for precision med, depression for pmh)--></p>
<p>Despite these opportunities for advances, however, precision mental health research has progressed with limited success. Extant research has not yet enabled reliable recommendations for treatment selection even at the group level - let alone for an individual patient. These patient-level predictions are required for clinical implementation; our goal in clinical science is to predict behavior such that we can apply findings to a new patient.</p>
<p>One reason for this slow progress is that many factors influence a complex clinical phenomenon like treatment success. Thus, any single feature (i.e., predictor variable) cannot account for more than a small portion of the variance in treatment success. This idea is perhaps comparable to the shift in understanding within genetics: research has moved away from candidate gene studies to polygenic approaches that rely on small contributions from many genes (Bogdan et al., 2018). Unfortunately, traditional analytic techniques have often limited the ability to consider more than one or a few features simultaneously. These limitations have also prevented considering concurrently features across constructs (e.g., demographics, psychological traits, environmental variables). Therefore, models have failed to capture the real-world complexity underlying these clinical phenomena.</p>
<p>Moreover, because researchers using traditional analytic techniques typically develop and evaluate their precision mental health models in a single sample, the models may become very overfit to that sample. Consequently, they do not generalize well to new patients that were not used for model development. This problem is particularly concerning because clinical implementation of precision mental health requires that these models provide accurate recommendations about treatment selection for <em>new</em> patients rather than explaining treatment success within the study sample.</p>
<p>These pitfalls interact with each other. To capture sufficient complexity to predict treatment success, we need to increase the total number of features in precision mental health models. Incorporating more features, however, makes overfitting the data more likely. Thus, successful precision mental health requires an analytic approach that can handle high-dimensional data without becoming too overfit to generalize to new patients.</p>
</section>
<section id="applying-machine-learning-approaches" class="level3">
<h3 class="anchored" data-anchor-id="applying-machine-learning-approaches">Applying machine learning approaches</h3>
<p>Applying machine learning to precision mental health research can address these limitations of traditional analytic techniques. Machine learning is an alternative analytic technique that uses statistical algorithms trained on high-dimensional arrays (hundreds or even thousands) of features8. Flexibly considering many features simultaneously means these models can tap the tangled web of constructs that comprise complex clinical phenomena. Critically, this allows researchers to consider many features in the same model – unlike previous precision mental health research that was limited to considering very few features simultaneously. This high dimensionality across and within sets of related features is necessary to explain a high portion of variance in person-level treatment success.</p>
<p>Although machine learning models can handle very large numbers of features, this capacity comes at a cost, referred to as the “bias-variance trade-off”9. Too many features (particularly correlated features) yield unstable models that vary strongly based on the data used to develop them. High variance compromises model generalizability because a high variance (e.g., very flexible) model may not predict very accurately in new data. However, too few features (as well as other constraints on model characteristics) yield biased models that also do not predict well because they miss important predictive patterns and relationships. Machine learning uses various techniques (e.g., regularization, hyperparameter tuning, simultaneous consideration of many model configurations) to optimize this bias-variance trade-off to accommodate high-dimensional sets of features while reducing overfitting.8,9 Thus, machine learning methods may allow us to build precision mental health models that both capture clinical complexity and generalize accurately to new data.</p>
<p>Finally, machine learning provides rigorous resampling techniques to fit and evaluate models in separate data9. Consequently, models generalize well to new patients because they are evaluated on out-of-sample prediction. In a simplest case, data can be divided into held-in and held-out samples. More sophisticated resampling techniques such as cross-validation involve dividing the data many times to create multiple held-in and held-out samples. These approaches offer significant advantages for 1) accurately selecting a best model among multiple model configurations, and 2) estimating how well that model will perform when applied to new data (e.g., new patients in a clinical setting). Applying machine learning can accomplish the goal in precision mental health of accurate, robust treatment selection for new patients.</p>
</section>
<section id="opportunities-to-improve-equity-in-mental-health-treatment" class="level3">
<h3 class="anchored" data-anchor-id="opportunities-to-improve-equity-in-mental-health-treatment">Opportunities to improve equity in mental health treatment</h3>
<p>Critically, the combination of machine learning methods with the precision mental health paradigm may be able to mitigate health disparities in our current treatment pipeline. Treatments are rarely designed or evaluated in diverse samples, though the NIH has launched some new initiatives to improve this disparity. This push becomes somewhat irrelevant, however, when we rely exclusively on treatments developed decades ago that were effective in homogeneous samples, and we discount treatments that were less effective within the research sample but may have worked well for people with characteristics or identities not well-represented in that sample. Unfortunately, the people who we failed to include in our treatment design and validation are also those who are often disproportionately affected by these exact health conditions or face additional barriers to receive effective treatment.</p>
<p>These problems have, in some ways, been amplified by early work in precision medicine and precision mental health. Studies often begin with retrospective samples before bringing the models built in those samples to new patients. Thus, these models may be likely to fail for the same people for whom our initial treatments fail - the model can only be as good as the data with which it was developed. However, when this research is done thoughtfully, there are clear opportunities to address health disparities.</p>
<p>First, we can make a concerted effort to build treatment selection models using data from previously completed trials where there was good representation across as many marginalized characteristics as possible. This may include demographic variables such as sex, gender identity, race, or ethnicity, among others. Other important characteristics to consider might include income, access to insurance, and geographic region.</p>
<p>In some contexts, it would be problematic to use predictors that tap into constructs delineating marginalized identities such as race or socioeconomic status. For example, making decisions about who gets insurance (or doesn’t) and who gets released earlier from prison (or doesn’t) based on race would be not only inappropriate but also discriminatory. However, in the precision mental health landscape, we are not deciding <em>who</em> gets treatment. Rather, we are deciding <em>which</em> treatment to give a specific patient. Thus, we can take advantage of experiential or symptomatological differences as a result of characteristics such as race, ethnicity, sex, income, or comorbid health conditions to improve treatment outcomes.</p>
<p>An additional way in which this approach can help mitigate health disparities is through access. Many of the individual difference features that could help build treatment selection models may be easily measured via self-report, and dimensionality reduction approaches can limit the number of features that need to be assessed. Consequently, treatment selection models might require sparse assessment of only a handful of readily available items and could even be implemented online. In cases where treatments are available over-the-counter, completing the assessment remotely means that individuals without insurance or access to in-person medical care can still give themselves the best chance of treatment success.</p>
</section>
<section id="cigarette-smoking-as-a-critical-precision-mental-health-target" class="level3">
<h3 class="anchored" data-anchor-id="cigarette-smoking-as-a-critical-precision-mental-health-target">Cigarette smoking as a critical precision mental health target</h3>
<section id="public-health-importance-of-cigarette-smoking" class="level4">
<h4 class="anchored" data-anchor-id="public-health-importance-of-cigarette-smoking">Public health importance of cigarette smoking</h4>
<p>Cigarette smoking could benefit greatly from combining precision mental health and machine learning. Smoking remains an enormous public health burden. Tobacco is the number one cause of preventable death in the U.S. and accounts for more than 480,000 deaths annually10-12. Although rates of smoking have declined considerably, approximately 14% of U.S. adults continue to smoke daily or near-daily10-12. Cigarette smoking rates also remain much higher in potentially vulnerable populations including: people with chronic or severe mental illness (Baker ARCP); Native American and non-Hispanic Black individuals (CDC 2007); individuals who are economically and educationally disadvantaged (CDC 2007); people with other substance use disorders (Kelly 2012); people in the criminal justice system (Cropsey Eldridge Ladner 2004; Harrison et al 2019); people experiencing homelessness (); people who are insured through Medicaid or uninsured (Jamal 2015); and individuals who identify as lesbian, gay, or bisexual (Jamal 2015).</p>
<!-- 
consider citing work about impact on longevity of extra years smoking
-->
</section>
<section id="smoking-cessation-treatment" class="level4">
<h4 class="anchored" data-anchor-id="smoking-cessation-treatment">Smoking cessation treatment</h4>
<p>Despite the severity of the problem, treatment has had relatively limited reach (CITE Baker ARCP review). A survey of almost 16000 US adults who use cigarettes showed that the most commonly used strategies by far to quit were giving up cigarettes all at once and gradually cutting back, with a much smaller proportion using evidence-based treatments (CITE Carabello 2017).</p>
<p>For those who do get treatment, the best available smoking cessation treatments are modestly effective. The medications varenicline and combination nicotine replacement therapy (C-NRT) are consistently identified as the most effective options when combined with psychosocial counseling (Cahill et al., 2013), and guidelines recommend that clinicians consider either of these two medications first given their established efficacy (Fiore et al., 2008). These medications appear to be equally (though modestly) effective: a meta-analysis demonstrated comparable effectiveness rates (Cahill et al., 2013), and the first randomized controlled trial (RCT) directly comparing varenicline and C-NRT did not find a difference between them (Baker et al., 2016).</p>
<p>Typically, 6-month abstinence rates hover around 30-35% for these best smoking cessation medications combined with psychosocial counseling13,14. Treatment with an FDA-approved medication doubles the likelihood that an individual will quit successfully (Baker ARCP). These rates represent a best-case scenario in that clinical trial data involve treatment regimens that are rigorously followed and optimized for adherence. Additionally, because several first-line (i.e., FDA-approved) smoking cessation treatments have comparable population-level effectiveness rates, population effectiveness alone cannot guide selection among smoking cessation treatments. These facts suggest a critical need for machine learning-assisted treatment selection in the cigarette smoking domain.</p>
<!-- ADD:
- information about typical # of quit attempts, support that tx is not very effective, though worse when they don't get treatment

-->
</section>
<section id="opportunities-for-differential-treatment-selection" class="level4">
<h4 class="anchored" data-anchor-id="opportunities-for-differential-treatment-selection">Opportunities for differential treatment selection</h4>
<!-- pilot data Cropsey et al 2017 - NRT "sampling" increases adherence to selected treatment -->
<p>National clinical guidelines note that “there are no well-accepted algorithms to guide optimal selection” between any of the first-line medications (Fiore et al., 2008, p.&nbsp;44). However, there may be reason to expect that some treatments may work better than others for a specific individual.</p>
<p>First, there is enormous heterogeneity among people who smoke cigarettes. Individuals may differ with respect to the etiology of their tobacco use disorder, the severity of their dependence and/or withdrawal symptoms, historical factors related to their tobacco use (e.g., age of first use, years smoking, number of previous quit attempts), and barriers to initiation and/or retention in smoking cessation treatments (Oliver &amp; McClernon, 2017; J. Wang, Simons-Morton, Farhat, Farhart, &amp; Luk, 2009; Zheng, Wiebe, Cleveland, Molenaar, &amp; Harris, 2013). These factors that affect the development and course of their disorder could include demographic traits, personal medical history, and many other key individual difference characteristics. However, this heterogeneity is typically neglected when selecting among available treatments.</p>
<p>Second, smoking cessation medications have distinct pharmacological mechanisms of action at nicotinic acetylcholine receptors (nAChRs), which may affect how helpful they are for different people. Nicotine replacement therapy (NRT) provides nicotine, a full agonist at nAChRs. Different NRTs provide nicotine differently. C-NRT consists of a nicotine patch and ad libitum nicotine lozenge use. The patch offers transdermal administration of a low, steady dose of nicotine. Some people who smoke cigarettes may rely on this low, steady nicotine level to replace nicotine from cigarettes. Lozenges provide oral administration of nicotine with more rapid onset, which could help individuals who need a quick boost during craving.</p>
<p>Other individuals who smoke may benefit from a medication like varenicline. In contrast to NRTs, varenicline is a partial agonist at nAChRs. Partial agonists have a pharmacological action that is somewhere between full agonists and antagonists, depending on the level of surrounding neurotransmitter. In the absence of a full agonist or endogenous neurotransmitter, partial agonists can act as a functional agonist with lower activity than a full agonist. In the presence of a full agonist (e.g., a cigarette) or endogenous neurotransmitter, however, they act as functional antagonists because their binding to the receptor limits the amount of binding from the full agonist and consequently reduces that response (Jordan &amp; Xi, 2018; Lieberman, 2004).</p>
<p>Thus, varenicline may be more pharmacologically flexible than NRT medications: when an individual is not smoking, it can produce milder, nicotine-like effects; if an individual begins smoking again, it could block or reduce full agonist (cigarette nicotine) activity at the receptor. This would be expected to reduce the pharmacological effect of nicotine, likely reducing the behavioral pleasure of smoking (Cahill, Lindson‐Hawley, Thomas, Fanshawe, &amp; Lancaster, 2016). Although C-NRT has some behavioral flexibility built in (i.e., combination of slow, steady dosing with faster-acting lozenges that can be used in response to internal states or environmental cues), it acts exclusively as a full agonist at nAChRs and cannot exert antagonist-like actions.</p>
<p>Third, features across several behavioral or environmental domains may also guide treatment selection, alone or in combination with medication mechanisms of action. For example, some cigarette smokers may have strong cravings with good self-monitoring. These characteristics may make treatments such as nicotine lozenges or gum more effective for those people because they are aware enough of their own craving to get a quick “hit” of nicotine when needed. Some smokers may be prone to side effects from a specific treatment, reducing adherence and subsequent likelihood of treatment success, though they may not have had the same adverse reactions to a different treatment. Environmentally, an individual who lives with other smokers may benefit from a partial agonist treatment like varenicline because any secondhand smoke would produce less effect. Any of these characteristics, among others, could powerfully inform treatment selection for cigarette smoking cessation. These examples illustrate the potential clinical benefit of using a precision mental health paradigm to inform treatment selection for smoking cessation. They also point to the value of analytic techniques that can incorporate complex interactions among features. Although these examples were selected because they are more intuitive, there are likely other unexpected ways that treatment success differs across people. Machine learning models are not limited to intuitive or theoretically derived features. Thus, machine learning may reveal unanticipated features that could meaningfully guide treatment selection for cigarette smoking cessation.</p>
<p>Finally, there is some evidence that individuals respond differently to different treatments. One large study that examined multiple medication-assisted quit attempts found that individuals who switched medications were more likely to quit than individuals who used the same medication again or who did not use a medication on the first quit attempt but added one at the second (Heckman et al., 2017). Relatedly, there is some evidence that re-treatment with the same medication as a previous, unsuccessful quit attempt is not effective; Gonzales and colleagues note that “abstinence rates are more than threefold lower for NRTs and twofold lower for bupropion” during re-treatment compared to initial treatment using the same medication (Gonzales et al., 2014, p.&nbsp;391; Fiore et al., 2008; Tønnesen, Nørregaard, Säwe, &amp; Simonsen, 1993). Additionally, clinical research related to other psychological and psychiatric disorders has demonstrated differential treatment benefit on an individual basis (e.g., antipsychotic medications for schizophrenia; Roussidis et al., 2013), suggesting it is worth investigating whether the same is true in smoking cessation.</p>
</section>
<section id="previous-precision-mental-health-machine-learning-research" class="level4">
<h4 class="anchored" data-anchor-id="previous-precision-mental-health-machine-learning-research">Previous precision mental health &amp; machine learning research</h4>
<!--
emphasize - certainly a lot of work has been done, but...
- suboptimal targets (not tx selection, more often predicting who will succeed or not, or whether an individual tx will work or not [cite study that we rebutted])
- using predictors that are not well-suited for implementation (e.g., genetics, biological measures)
- don't produce an actionable tool 

Substance use researchers have employed machine learning algorithms to identify problematic drug use (Ahn, Ramesh, Moeller, & Vassileva, 2016; Ding, Bickel, & Pan, 2017; Mete et al., 2016; Squeglia et al., 2017). Less work has been conducted examining clinical outcomes (instead of diagnoses), although some researchers have used this approach to predict SUD treatment completion (Steele et al., 2018) and treatment response (Acion et al., 2017), and even to detect posts that merited intervention via text analysis of risky words in online recovery forums (Kornfield et al., 2018).

Other researchers have examined characteristics such as impulsivity and sensation-seeking (Tomko et al 2016), comorbid disorders (Luo & Levin 2017), and genetics (Sun et al 2016) in an attempt to personalize treatment among subgroups of individuals with substance use disorders. Within the context of cigarette smoking, Piper and colleagues have identified several moderators that affect treatment response and cessation such as smoking heaviness, psychiatric history, and use of pre-quit interventions like nicotine gum (cite two Piper 2017 articles). 

incorporate new articles (in zotero)

LOTS of work in genetics especially related to nicotine metabolism ratio (variants in the CYP2A6 gene), slower metabolizers may do better with NRT and faster metabolizers may do better with varenicline (Chenoweth et al 2016, Kaufmann 2015, Schnoll 2009, Glatard 2017, Shahab 2019, Lerman 2015). also nicotinic receptor gene (Chen 2020, Schuit 2017) - individuals of non-European ancestry with GG genotype perform better with CNRT than with varenicline, those with GA/AA genotypes had higher abstinence rates with varenicline -- a lot of this is less exciting/certain than discussed in the baker arcp paper! caution!!! also often still has problems of predicting who will succeed or not (eg ok if you are a fast metabolizer, varenicline gives you a better chance than patch, but what do you do if you're a slow metabolizer?!). review chen horton bierut 2018 re: genetics/pm/smoking
-->
</section>
</section>
<section id="purpose" class="level3">
<h3 class="anchored" data-anchor-id="purpose">Purpose</h3>
<!-- as AIMS? or just "paragraph" form? -->
</section>
</section>
<section id="methods" class="level2">
<h2 class="anchored" data-anchor-id="methods">Methods</h2>
<section id="transparency-openness" class="level3">
<h3 class="anchored" data-anchor-id="transparency-openness">Transparency &amp; openness</h3>
<!-- NTS: already correct OSF page -->
<p>We adhere to research transparency principles that are crucial for robust and replicable science. We reported how we determined the sample size, all data exclusions, all manipulations, and all study measures. We provide a transparency report in the supplement. Finally, our data, analysis scripts, annotated results, questionnaires, and other study materials are publicly available (<a href="https://osf.io/qad4n/">https://osf.io/qad4n/</a>).</p>
<p>We preregistered our analyses to evaluate clinical benefit that relied on significance testing. The preregistration can be found on our OSF page (<a href="https://osf.io/qad4n/">https://osf.io/qad4n/</a>). For our Bayesian hierarchical generalized linear models, we followed guidelines from the tidymodels team (CITE) that we have followed in other published research from our laboratory (Wyant et al., in press). For all other analyses, we restricted many researcher degrees of freedom via cross-validation. Cross-validation inherently includes replication: models are fit on held-in training sets, decisions are made in held-out validation sets, and final performance is evaluated on held-out test sets.</p>
</section>
<section id="data" class="level3">
<h3 class="anchored" data-anchor-id="data">Data</h3>
<p>The data for this project came from a completed randomized controlled trial conducted by the University of Wisconsin (UW) Center for Tobacco Research and Intervention (CTRI)21. This trial compared the effectiveness of three cigarette smoking cessation treatments (varenicline, combination nicotine replacement therapy [C-NRT], and nicotine patch). Briefly, 1086 daily cigarette smokers were enrolled in Madison, WI, USA and Milwaukee, WI, USA. Exclusion criteria included contraindicated medical (e.g., severe hypertension) or psychiatric conditions (e.g., severe and persistent mental illness), current use of contraindicated medications, and pregnancy or unwillingness to use appropriate methods of contraception while taking a study medication. Participants set a quit date with study staff and were enrolled for several weeks prior to the target quit date through at least 6 months following quitting smoking.</p>
<section id="treatment-conditions" class="level4">
<h4 class="anchored" data-anchor-id="treatment-conditions">Treatment conditions</h4>
<p>Participants were randomly assigned to receive 12 weeks of medication treatment plus 6 sessions of motivational and skill-training counseling per clinical guidelines (CITE FIORE GUIDELIINES). For varenicline, participants began medication use prior to their quit attempt, starting with 0.5 mg once daily for 3 days, followed by 0.5 mg twice daily for 4 days, and 1 mg twice daily for 3 days. They continued use of 1 mg twice daily for 11 weeks following their quit date except in response to adverse effects. For C-NRT or nicotine patch, participants began using the patch on their quit date, starting with 21 mg for 8 weeks, followed by 14 mg for 2 weeks, and 7 mg for 2 weeks. All individuals who received C-NRT were also instructed to use 5 lozenges per day (2 or 4 mg nicotine lozenges determined by time to first daily cigarette) for the full 12 weeks except in the case of adverse effects.</p>
</section>
<section id="individual-difference-characteristics" class="level4">
<h4 class="anchored" data-anchor-id="individual-difference-characteristics">Individual difference characteristics</h4>
<p>Participants were comprehensively assessed for individual differences characteristics prior to treatment randomization. These characteristics fall into several domains expected to relate to cigarette smoking cessation: tobacco-related (e.g., cigarettes per day), psychological (e.g., psychiatric diagnoses, distress tolerance), physical health (e.g., vital signs), social/environmental (e.g., living with another person who smokes), and demographic (e.g., age, sex). A detailed list of all available individual differences variables appears in Table X.</p>
<!-- more text here or ok just to refer to a detailed table? -->
</section>
<section id="abstinence-outcome" class="level4">
<h4 class="anchored" data-anchor-id="abstinence-outcome">Abstinence outcome</h4>
<p>Throughout study participation, participants were assessed for biologically confirmed, 7-day point-prevalence abstinence. Participants self-reported whether they had smoked over the past 7 days, and their report was biologically confirmed via exhaled carbon monoxide (CO). Participants were labeled as “abstinent” if their CO level was less than 6 parts per million (ppm; Baker et al., 2016). If participants self-reported smoking in the past 7 days, their CO level contradicted their self-report (i.e., CO level &gt; 6 ppm), or biological confirmation could not be confirmed, participants were labeled as “smoking.” Participants were assessed for abstinence periodically beginning 4 week post-quit through the end of their study participation. Our <em>primary prediction outcome</em> for our models was point-prevalence abstinence at 4 weeks post-quit.</p>
</section>
</section>
<section id="aim-1-analytic-strategy-model-building" class="level3">
<h3 class="anchored" data-anchor-id="aim-1-analytic-strategy-model-building">AIM 1 analytic strategy: Model building</h3>
<section id="feature-engineering-and-dimensionality-reduction" class="level4">
<h4 class="anchored" data-anchor-id="feature-engineering-and-dimensionality-reduction">Feature engineering and dimensionality reduction</h4>
<p>Feature engineering is the process of converting raw predictors into meaningful numeric and/or categorical representations (features) that improve model effectiveness (CITE kuhn feature engineering). A sample feature engineering script (i.e., tidymodels recipe) containing all feature engineering steps is available on our OSF study page (<a href="https://osf.io/qad4n/">https://osf.io/qad4n/</a>). Our generic feature engineering steps included: 1) imputing missing data (median imputation for numeric features, mode imputation for nominal and ordinal features); and 2) removing zero-variance features. Medians/modes for missing data imputation and identification of zero variance features were derived from held-in (training) data and applied to held-out (validation and test) data (see Cross-validation section below).</p>
<p>We used a Yeo-Johnson transformation on all numeric variables to address distributional shape. Unordered categorical variables were dummy-coded. Ordered categorical variables (e.g., Likert scale items on self-report measures) could be ordinal scored (i.e., treated as numeric data) or dummy-coded. We also allowed treatment (dummy coded) to interact with all other features. Finally, all features were normalized as a requirement of the GLMNet algorithm.</p>
<p>Although machine learning methods can handle high-dimensional data, there is a cost to including a high ratio of features to observations (“<em>p</em> to <em>n</em> ratio”). Models were <em>p</em> &gt; <em>n</em> are possible with machine learning; however, models can become easily overfit and therefore not generalizable to new data. Thus, we used several dimensionality reduction approaches to reduce the number of features in my models. We used data-driven methods for dimensionality reduction including: removing highly correlated or near-zero variance features, and considering feature engineering approaches that reduced the number of overall features (e.g., ordinal scoring vs.&nbsp;dummy coding). The algorithm GLMNet also inherently conducts dimensionality reduction by penalizing model complexity such that features’ predictive value must outweigh the cost of including an additional parameter in the model.</p>
<p>We also used several non-data-driven approaches for dimensionality reduction. First, we used domain knowledge to reduce dimensionality by removing features that lacked face validity for predicting abstinence or overlapped conceptually with other features. Second, we removed variables that stood in contrast to the ultimate implementation goals (e.g., variables whose assessment required blood work or lab tests).</p>
</section>
<section id="model-training-and-evaluation" class="level4">
<h4 class="anchored" data-anchor-id="model-training-and-evaluation">Model training and evaluation</h4>
<section id="model-configurations" class="level5">
<h5 class="anchored" data-anchor-id="model-configurations">Model configurations</h5>
<!-- 
We trained and evaluated two separate sets of classification models: one predicting 4-week abstinence, and one predicting 26-week (6 month) abstinence. 

likely going to have 6-month models only in supplement
-->
<p>All model configurations used the statistical algorithm Elastic Net Logistic Regression (GLMNet). This algorithm aligns with our primary goal of building a treatment selection model in several ways. First, it allows for explicit inclusion of interaction terms (i.e., including interactions between treatment and all other variables). This permits capturing multiple interactions that each account for a small portion of variance. Second, GLMNet performs a degree of dimensionality reduction because it penalizes model complexity; thus, a model using this algorithm may require assessing fewer features than are initially considered in the model. This characteristic aligns with our intention to implement this model in clinical practice, where highly burdensome assessments are impractical and thereby not feasible. Finally, linear models such as GLMNet are often more interpretable and transparent because they produce parameter estimates for the features in the model. Initial testing showed that GLMNet outperformed or performed comparably to models fit using several other well-established statistical algorithms (XGBoost, Random Forest). Thus, we had no reason not to prefer an algorithm that aligned well with our ultimate clinical goals.</p>
<p>Candidate model configurations differed across sensible values of the hyperparameters alpha and lambda (GLMNet tuning parameters). We also considered several outcome resampling techniques: no resampling, up-sampling, down-sampling, and the synthetic minority oversampling technique (SMOTE). These resampling techniques were used to create majority/abstinence to minority/smoking ratios in the held-in training data ranging from 2:1 to 1:1 (natural rate in data ~3:1).</p>
<p>We considered several feature sets across model configurations. Feature sets could include either items (i.e., individual items within a self-report measure) or scales (i.e., total scale and sub-scale scores derived from items in a self-report measure). All other features (e.g., demographic variables) were included across model configurations.</p>
<p>Feature engineering steps also differed across model configurations regarding how ordinal data were scored. Specifically, ordinal data could be considered as numeric (e.g., 1 - 7) or dummy coded (e.g., 7 dummy code features for a 7-level variable). Numeric and unordered nominal data were treated identically across configurations.</p>
</section>
<section id="performance-metric" class="level5">
<h5 class="anchored" data-anchor-id="performance-metric">Performance metric</h5>
<!-- add citations for paper(s) in paper_match about roc -->
<p>Our primary performance metric for model selection and evaluation was area under the Receiver Operating Characteristic Curve (auROC) [CITE kuhnAppliedPredictiveModeling2018]. auROC indexes the probability that the model will predict a higher score for a randomly selected positive case (lapse) relative to a randomly selected negative case (no lapse). This metric was selected because it 1) combines sensitivity and specificity, which are both important characteristics for clinical implementation; and 2) is unaffected by class imbalance, which is important for comparing models with differing levels of class imbalance.</p>
</section>
<section id="cross-validation" class="level5">
<h5 class="anchored" data-anchor-id="cross-validation">Cross-validation</h5>
<!-- add citations for paper in paper_match folder about problems with selecting & evaluating in same sample -->
<p>We used nested cross-validation for model training, selection, and evaluation with auROC. Cross-validation allows for rigorous consideration of many model configurations (i.e., combinations of feature sets, statistical algorithms, resampling techniques, and hyperparameters) and prioritizes performance in new data not used for model training.</p>
<p>Nested cross-validation uses two nested loops for dividing and holding out folds: an outer loop, where held-out folds serve as <em>test sets</em> for model evaluation; and inner loops, where held-out folds serve as <em>validation sets</em> for model selection. Importantly, these sets are independent, maintaining separation between data used to train the models, select the best models, and evaluate those best models. Therefore, nested cross-validation removes optimization bias from the evaluation of model performance in the test sets and can yield lower variance performance estimates than single test set approaches [ CITE jonathanUseCrossvalidationAssess2000].</p>
<p>We used 1 repeat of 10-fold cross-validation for the inner loops and 3 repeats of 10-fold cross-validation for the outer loop. Best model configurations were selected using median auROC across the 10 <em>validation sets</em>. Final performance evaluation of those best model configurations used median auROC across the 30 <em>test sets</em>. We report median auROC for our best model configurations for each model (4-week and 26-week) in the test sets. For completeness, we also report auROCs for these models from the validation sets in the Supplement. In addition, we report other key performance metrics for the best full model configurations including sensitivity, specificity, balanced accuracy, positive predictive value (PPV), and negative predictive value (NPV) from the test sets [CITE kuhnAppliedPredictiveModeling2018].</p>
<p>Following model evaluation, we completed another round of 1 repeat of 10-fold cross-validation using the full dataset. A single best model configuration was selected using median auROC across the 10 held-out folds; importantly, model performance is used <em>only</em> for selection and not evaluation in this phase. We fit our final model using this best model configuration in the full dataset, which was then used for clinical benefit analyses (below).</p>
</section>
</section>
<section id="evaluation-of-model-performance" class="level4">
<h4 class="anchored" data-anchor-id="evaluation-of-model-performance">Evaluation of model performance</h4>
<!-- add bayesian citations from paper_match folder -->
<p>We used a Bayesian hierarchical generalized linear model to estimate the posterior probability distributions and 95% Bayesian confidence intervals (CIs) for auROC for the best models. Posterior probability is the likelihood of obtaining our results given our data. A posterior probability distribution around a given parameter (e.g., median auROC) allows us to assess the certainty of our results.</p>
<p>To estimate the probability that the 4-week model outperformed the 26-week model, we regressed the auROCs (logit transformed) from the 30 test sets for each model as a function of outcome (4-week vs.&nbsp;26-week). Following recommendations from the tidymodels team [CITE kuhnTidyposteriorBayesianAnalysis2022], we set two random intercepts: one for the repeat, and another for the fold within repeat (folds are nested within repeats for 3x10-fold cross-validation). We report the 95% (equal-tailed) Bayesian CIs from the posterior probability distributions for our models’ auROCs. If 95% Bayesian CIs do not include 0.5 (chance performance), we can conclude that the model performs better than chance. We also report 95% (equal-tailed) Bayesian CIs for the differences in performance associated with the Bayesian comparisons. If the 95% Bayesian CI around a difference in performance does not include 0, we can conclude that one model performs better than the other.</p>
<p>Bayesian analyses were accomplished using the tidyposterior [CITE kuhnTidyposteriorBayesianAnalysis2022] and rstanarm [CITE goodrichRstanarmBayesianApplied2023] packages in R. Following recommendations from the rstanarm team and others [CITE rstudioteamRStudioIntegratedDevelopment2020; CITE gabryPriorDistributionsRstanarm2023], we used the rstanarm default autoscaled, weakly informative, data-dependent priors that take into account the order of magnitude of the variables to provide some regularization to stabilize computation and avoid over-fitting. Specifically, the priors were set as follows: residual standard deviation ~ normal(location=0, scale=exp(2)), intercept (after centering predictors) ~ normal(location=2.3, scale=1.3), the two coefficients for window width contrasts ~ normal (location=0, scale=2.69), and covariance ~ decov(regularization=1, concentration=1, shape=1, scale=1). <!-- UPDATE PRIORS these are from ema supplement --></p>
</section>
<section id="feature-importance-with-shap" class="level4">
<h4 class="anchored" data-anchor-id="feature-importance-with-shap">Feature importance with SHAP</h4>
<p>We computed Shapley Values [CITE lundbergUnifiedApproachInterpreting2017] to provide a consistent, objective explanation of the importance of categories of features (based on EMA questions) across our three full models. Shapley values possess several useful properties including: Additivity (Shapley values for each feature can be computed independently and summed); Efficiency (the sum of Shapley values across features must add up to the difference between predicted and observed outcomes for each observation); Symmetry (Shapley values for two features should be equal if the two features contribute equally to all possible coalitions); and Dummy (a feature that does not change the predicted value in any coalition will have a Shapley value of 0).</p>
<p>We calculated Shapley values for the best model configuration from the 10 held-out folds in the final 1X 10-fold cross-validation used to select the final model. We used the DALEX (CITE) and DALEXtra (CITE) packages in R, which provide Shapley values in log-odds units for binary classification models. These Shapley values estimate local importance (i.e., for each observation). To calculate global importance (i.e., across all observations), we averaged the absolute value of the Shapley values of each feature across observations. These local and global importance scores based on Shapley values allow us to answer questions of relative feature importance; however, these are descriptive analyses because standard errors or other indices of uncertainty for importance scores are not yet available for Shapley values.</p>
<!-- TBD:
The additivity property of Shapley values allowed us also to examine the relative importance of categories of features. We created two kinds of feature categories. First, we examined feature importance within a single self-report measure (e.g., all features derived from items from a specific measure). Second, we examined feature importance within a domain: demographic features, mental health features, physical health features, smoking use history, and social/environmental features. To calculate the local importance for each category of features, we added Shapley values across all features in a category, separately for each observation. To calculate global feature importance for each feature category, we averaged the absolute value of the Shapley values of all features in the category across all observations.

nts: "domain" grouping (second idea in above paragraph) was used similarly by PATH paper, and i liked it there
-->
</section>
</section>
<section id="aim-2-analytic-strategy-evaluation-of-clinical-benefit" class="level3">
<h3 class="anchored" data-anchor-id="aim-2-analytic-strategy-evaluation-of-clinical-benefit">AIM 2 analytic strategy: Evaluation of clinical benefit</h3>
<section id="identify-model-predicted-best-treatment" class="level4">
<h4 class="anchored" data-anchor-id="identify-model-predicted-best-treatment">Identify model-predicted best treatment</h4>
<p>The preregistration for our analyses evaluating clinical benefit can be found on our OSF page (<a href="https://osf.io/qad4n/">https://osf.io/qad4n/</a>). Using our final model (best selected model configuration fit on all data), we calculated three predictions for each participant by substituting each treatment into the model inputs. Thus, there is one prediction per person per treatment. For example, an individual may have received varenicline in the original trial. We calculated their probability of abstinence using their data, and then we calculated two additional probabilities by substituting C-NRT and nicotine patch for varenicline. These substitutions affected the probabilities through any main effect of treatment and any interactions of treatment with other features.</p>
<p>The treatment that yields the highest model-predicted probability of abstinence is identified as that participant’s “best” treatment. For example, among the three calculated probabilities for an individual, their probability of abstinence may be highest when C-NRT is substituted in as their treatment. This would mean C-NRT is identified as the best treatment for that person.</p>
</section>
<section id="categorize-treatment-matching" class="level4">
<h4 class="anchored" data-anchor-id="categorize-treatment-matching">Categorize treatment “matching”</h4>
<p>Some participants’ best treatment matched what they were randomly assigned in the original trial. Other participants may have received a sub-optimal treatment (i.e., what the model identified as their second-best or worst treatment based on calculated probabilities). Thus, participants’ RCT-assigned treatment can be categorized by whether it “matched” their model-selected treatment.</p>
</section>
<section id="evaluate-clinical-benefit" class="level4">
<h4 class="anchored" data-anchor-id="evaluate-clinical-benefit">Evaluate clinical benefit</h4>
<p>Our primary analysis to evaluate the clinical benefit of our model-selected treatment compared the observed outcomes (i.e., abstinence vs.&nbsp;smoking from the original trial) for people who did or did not receive their best treatment. Treatment matching was thus a between-subjects predictor and was coded as 0.5 (TRUE) vs.&nbsp;-0.5 (FALSE).</p>
<p>We examined this effect over time at 4, 12, and 26 weeks by allowing the effect of treatment match to interact with time (i.e., week). Time was a within-subjects variable with three repeated measures for each participant. We treated time numerically, and we used a log transformation (base 2) to meet linearity assumptions. Thus, our model included treatment match, time, the interaction between treatment match and time, a by-subject random slope for time, and a by-subject random intercept.</p>
<p>We followed a mixed-effects modeling approach using the blme package (Chung et al., 2013). Specifically, we fit a partially Bayesian generalized linear model that uses regularizing priors to force the estimated random effects variance-covariance matrices away from singularity (Chung et al., 2013). If the interaction between treatment match and time was significant, we planned to conduct follow-up tests of the simple effect of treatment match at each time point (week 4, week 12, and week 26) using general linear models.</p>
<p>We identified the main effect of treatment match <em>a priori</em> as our focal effect; however, we report all estimates, test statistics, <em>p</em>-values, and confidence intervals from all models.</p>
<!-- POSSIBLE
exploratory analyses
- 1/2/3 rank
- time as categorical (2 models)
-->
</section>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<!-- need to insert all values & figure numbers -->
<section id="sample-characteristics" class="level3">
<h3 class="anchored" data-anchor-id="sample-characteristics">Sample characteristics</h3>
<p>analysis sample inclusion criteria and final sample size here (full sample) descriptive statistics on demographics and maybe some tobacco-related characteristics tables</p>
</section>
<section id="model-performance" class="level3">
<h3 class="anchored" data-anchor-id="model-performance">Model performance</h3>
<p>We selected the best model configurations using auROCs from the <em>validation sets</em>. We report the median and IQR auROCs from the validation sets for these best model configurations in the Supplement. We evaluated these best model configurations using <em>test set</em> performance to remove optimization bias present in performance metrics from validation sets.</p>
<p>The median auROC across the 30 test sets for the 4-week model was XX (IQR = XX - XX, range = XX - XX). The median auROC across the 30 test sets for the 26-week model was XX (IQR = XX - XX, range = XX - XX). Additional performance metrics (not used for selection or primary evaluation) are reported in the Supplement.</p>
<p>We used the 30 test set auROCs to estimate the posterior probability distribution for the auROC of these models. The median auROCs from these posterior distributions were XX (4-week model) and XX (26-week model). These values represent our best estimates for the magnitude of the auROC parameter for each model. The 95% Bayesian CI for the auROCs were relatively narrow and did not contain 0.5 (chance performance) for either the 4-week model [XX - XX] or the 26-week model [XX - XX]. Figure X displays posterior probability distributions for the auROC for the models by outcome.</p>
<section id="bayesian-model-comparisons" class="level4">
<h4 class="anchored" data-anchor-id="bayesian-model-comparisons">Bayesian model comparisons</h4>
<p>We used the posterior probability distributions for the auROCs to compare formally the 4- and 26-week models. The median increase in auROC for the 4- vs.&nbsp;26-week model was XX (95% CI = [XX - XX]), yielding a probability of XX% that the 4-week model had superior performance. Figure X presents histograms of the posterior probability distributions for this model contrast.</p>
</section>
</section>
<section id="feature-importance" class="level3">
<h3 class="anchored" data-anchor-id="feature-importance">Feature importance</h3>
<section id="parameter-estimates-for-retained-variables" class="level4">
<h4 class="anchored" data-anchor-id="parameter-estimates-for-retained-variables">Parameter estimates for retained variables</h4>
<p>The glmnet algorithm offers two advantages with respect to understanding variable importance. First, the algorithm performs regularization using the hyperparameter alpha. This hyperparameter penalizes model complexity by shrinking parameter estimates and/or removing unimportant variables from the model entirely. Thus, variables are retained in the model only to the degree to which their contribution to performance outweighs the cost of having an additional parameter in the model. Consequently, we can review the retained predictor variables as a metric of feature importance.</p>
<p>The best 4-week model configuration retained XX features (best model configuration alpha = XX). Of the XX retained features, XX were treatment interaction variables, suggesting the importance of these interactions for prediction. These retained features require assessing XX unique items (e.g., multiple dummy variables are from a single item, an item is retained in an additive and interactive feature). Table X presents the retained features from the 4-week model configuration and their parameter estimates.</p>
<p>The best 26-week model configuration retained XX features (best model configuration alpha = XX). Of the XX retained features, XX were treatment interaction variables, suggesting the importance of these interactions for prediction. These retained features require assessing XX unique items (e.g., multiple dummy variables are from a single item, an item is retained in an additive and interactive feature). Table X presents the retained features from the 26-week model configuration and their parameter estimates.</p>
<!-- 
4-week best model as of now: 

128 features retained (out of 1173; 10.91%)

unique items required for differential prediction: 
live with smoker (MC), 
race, 
wisdm 2 & 5 & 13 & 14 & 16 & 18 & 19 & 20 & 22 & 26 & 27 & 30 & 32, 
smoke menthol y/n, 
used cigars (MC), 
close smoking friend y/n, 
dts 5 & 13 & 15, 
asi3 2 & 9 & 15, 
spouse smoke (MC), 
close smoking coworker y/n, 
dsm5 3 & 6 & 7 & 8 & 10 & 12, 
marital status, 
mfi 5 & 6 & 9 & 13 & 15, 
close smoking relative y/n, 
income, 
depression dx, 
work ban (MC), 
ftnd 1 & 2 & 6, 
berlin 7, 
tried nicotine gum y/n, 
wsws constipation & want cigarette & unhappy & 18 & 5 & 9 & angry & stressed & 12 & crave & 26 & coughing, 
life satisfaction, 
used pipe (MC), 
gender, 
carbon monoxide, 
motive for quitting, 
longest quit, 
time around smokers on weekend, 
shp 2 & 3 & 9 & 13 & 14, 
total quit attempts, 
importance to quit, 
sip2r 2 & 3 & 4, 
hdsm tense & pain
time around smokers
30-day quit success
phq9 6
used chew or snuff (MC)
used ecig (MC)
hrqol 4

- total: 83 unique items required for overall prediction

56 of those are treatment interactions (43.75% of retained features, 6% of 879 available treatment interaction features)

unique items required for differential prediction: 
live with smoker (MC), 
race, 
wisdm 16 & 18 & 19 & 22 & 26 & 27 & 30 & 32, 
smoke menthol y/n, 
used cigars (MC), 
close smoking friend y/n, 
dts 5, 
asi3 2 & 15, 
spouse smoke (MC), 
close smoking coworker y/n, 
dsm5 3 & 6 & 7 & 10, 
marital status, 
mfi 6 & 13, 
close smoking relative y/n, 
income, 
depression dx, 
work ban (MC), 
ftnd 2 & 6, 
berlin 7, 
tried nicotine gum y/n, 
wsws constipation, 
life satisfaction, 
used pipe (MC), gender

- total: 37 unique items required for treatment selection

(potential for some items to be combined eg people close to you who smoke, check all that apply)

-->
</section>
<section id="shapley-values" class="level4">
<h4 class="anchored" data-anchor-id="shapley-values">Shapley values</h4>
<p>Global importance (mean |Shapley value|) for features for each model appear in Panel A of Figure X. XX was the most important feature category across prediction outcomes. XX, XX, and XX were also globally important across models. XX, XX, and XX were the most relatively important treatment interaction variables.</p>
<p>Sina plots of local Shapley values (i.e., the influence of features on individual observations) for each model show that some features (e.g., XX, XX, XX) impact abstinence probability for specific individuals even if they are not globally important across all observations (Figure X, Panels B-C).</p>
<!-- TBD: feature categories in addition to individual features -->
</section>
</section>
<section id="clinical-benefit" class="level3">
<h3 class="anchored" data-anchor-id="clinical-benefit">Clinical benefit</h3>
<p>4 &amp; 26 weeks</p>
<p>main effect of tx_match</p>
<p>tx_match X time interaction - follow-up simple effects if needed</p>
<p>supplemental aim 2 analyses: 1/2/3 tx rank?</p>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<!-- IGNORE FOR NOW

from nrsa innovation & impact:

The proposed project combines machine learning with precision mental health to select among treatments for cigarette smoking cessation. Machine learning remains novel and underused in substance use and, to some degree, clinical psychology broadly16. Further, prior machine learning research for SUDs has prioritized diagnosis and screening17–20 over treatment selection, highlighting the novelty of this project.

This project is also innovative in that it will consider a wide variety of features within and across domains (e.g., smoking history, other substance use, psychological traits/conditions, physical health, demographics, social environment). Machine learning methods allow me to incorporate these features simultaneously and build high-dimensional models that capture real-world complexities. Including features across domains invites interactions among features and subsequent integration of knowledge across domains. The proposed project will allow features often considered disparate to interact with one another, permitting combinations of features that are both guided by domain expertise and driven by less intuitive patterns in the data.

This project could provide immediate impact by offering a decision-making tool for selecting among smoking cessation treatments. My model would provide patient-level guidance for treatment selection among smoking cessation treatments, which would reduce health risks and societal burdens. Critically, this approach could offer those benefits without requiring new treatment development, which is time- and resource-intensive. Instead, we can improve treatment effectiveness by optimizing therapeutic benefit of existing treatments. 

I aim to increase potential impact by allowing feasibility to guide model development. I will prioritize sparse models with readily available, easy-to-measure features to the degree that these models yield robust treatment selection. The available features set can be easily measured via self-report. Easy measurement would allow our decision-making tool to be implemented without blood draws, expensive or otherwise inaccessible testing (e.g., neuroimaging), formal clinical interviewing, or even in-person doctors’ visits. In fact, prioritizing feasibility is a primary rationale for excluding genetic features from the present project; genetic features would require specialty materials and/or in-person medical appointments during clinical implementation. An assessment constructed entirely from self-report measurements is particularly valuable because two treatments in the model (nicotine patch, combination NRT) are widely available over the counter, offering scalable implementation even when medical access is limited. This focus on feasibility (i.e., using low burden, low-cost features) could maximize potential clinical benefit. These efforts are especially warranted when applying the precision mental health paradigm to SUDs, for which large health disparities on the bases of race, ethnicity, socioeconomic status, and geographic location persist.

lots of stuff in baker arcp re: meds are not nearly as effective in real-world settings. NEED LONGER TERM SUPPORT!!!

-->
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<div id="refs" role="list">

</div>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{e fronk2024,
  author = {E Fronk, Gaylen and J. Curtin, John},
  title = {Machine Learning-Assisted Treatment Selection for Smoking
    Cessation},
  date = {2024-05-13},
  langid = {en},
  abstract = {This study found some pretty cool results that have both
    high impact and important clinical implications. For example ...}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-e fronk2024" class="csl-entry quarto-appendix-citeas" role="listitem">
E Fronk, Gaylen, and John J. Curtin. 2024. <span>“Machine
Learning-Assisted Treatment Selection for Smoking Cessation.”</span>
Journal of Important Findings. May 13, 2024.
</div></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>