{
  "hash": "1907e0daebd960440736d208d293e733",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Posterior probabilities across models for Insight study (version v5)\"\nauthor: \"John Curtin\"\ndate: \"2024-04-09\"\nformat:\n  html:\n    embed-resources: true\nparams:\n  study: \"match\"\n  version: \"v5\"\n  y_col_name: \"pp_hybrid_wk4_outcome\"\n  cv: \"nested\"\noutput: \n  html_document:\n    toc: true \n    toc_depth: 4\neditor_options: \n  chunk_output_type: console\n---\n\n\n### Code Status\n\nIn use with iterative improvement.\n\nUpdating for use with MATCH\n\n### Notes\nCan review online docs for \n\n* [how to use rstanarm](https://cran.r-project.org/web/packages/rstanarm/vignettes/rstanarm.html)\n* [priors](https://cran.r-project.org/web/packages/rstanarm/vignettes/priors.html)\n* [warnings](https://mc-stan.org/misc/warnings.html)\n* [tutorial on rstanarm and shinystan](https://www.tqmp.org/RegularArticles/vol14-2/p099/p099.pdf)\n* [R Bloggers on perf_mod](https://www.r-bloggers.com/2019/12/tidyposteriors-bayesian-approach-to-model-comparison/)\n\n### Set Up Environment\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nstudy <- params$study\nversion <- params$version\ncv <- params$cv\n```\n:::\n\n\nPackages for script\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(tidyposterior)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tune         1.1.2\n✔ infer        1.0.6     ✔ workflows    1.1.3\n✔ modeldata    1.3.0     ✔ workflowsets 1.0.1\n✔ parsnip      1.1.1     ✔ yardstick    1.3.0\n✔ recipes      1.0.9     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\ntheme_set(theme_classic()) \n```\n:::\n\n\nAbsolute paths\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nswitch (Sys.info()[['sysname']],\n        # PC paths\n        Windows = {\n          path_models <- \"P:/studydata/match/models/\"},\n        \n        # IOS paths\n        Darwin = {\n          path_models <- \"/Volumes/private/studydata/match/models/\"},\n        \n        # Linux paths\n        Linux = {\n          path_models <- \"~/mnt/private/studydata/match/models/\"}\n)\n```\n:::\n\n\n\nChunk Defaults\n\n::: {.cell .hidden}\n\n```{.r .cell-code .hidden}\nknitr::opts_chunk$set(attr.output='style=\"max-height: 500px;\"')\n\noptions(tibble.width = Inf)\noptions(tibble.print_max = Inf)\n```\n:::\n\n\n\nSource training controls \n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# EDA\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"c045eee2655a18dc85e715b78182f176327358a7\"\n```\n\n\n:::\n:::\n\n\n\n### Read in preds and metrics for best model\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nauc_wk4 <- read_rds(file.path(path_models, \"pp_hybrid_wk4_outcome\",\n                              str_c(\"outer_metrics_\", \n                                    version, \"_\", cv, \".rds\"))) |> \n  arrange(outer_split_num) |> \n  mutate(repeat_num = rep(str_c(\"repeat\", 1:3), each = 10),\n         fold_num = rep(str_c(\"fold\", 1:10), 3)) |>   # assumes 3x10 fold\n  select(repeat_num, fold_num, roc_auc) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\nRows: 30\nColumns: 3\n$ repeat_num <chr> \"repeat1\", \"repeat1\", \"repeat1\", \"repeat1\", \"repeat1\", \"rep…\n$ fold_num   <chr> \"fold1\", \"fold2\", \"fold3\", \"fold4\", \"fold5\", \"fold6\", \"fold…\n$ roc_auc    <dbl> 0.5890269, 0.7058600, 0.6805259, 0.6269727, 0.7406656, 0.75…\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nauc_wk26 <- read_rds(file.path(path_models, \"pp_hybrid_wk26_outcome\",\n                               str_c(\"outer_metrics_\", \n                                     version, \"_\", cv, \".rds\"))) |> \n  arrange(outer_split_num) |> \n  mutate(repeat_num = rep(str_c(\"repeat\", 1:3), each = 10),\n         fold_num = rep(str_c(\"fold\", 1:10), 3)) |>   # assumes 3x10 fold\n  select(repeat_num, fold_num, roc_auc) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\nRows: 30\nColumns: 3\n$ repeat_num <chr> \"repeat1\", \"repeat1\", \"repeat1\", \"repeat1\", \"repeat1\", \"rep…\n$ fold_num   <chr> \"fold1\", \"fold2\", \"fold3\", \"fold4\", \"fold5\", \"fold6\", \"fold…\n$ roc_auc    <dbl> 0.6405063, 0.6494382, 0.6066667, 0.5852641, 0.6827004, 0.63…\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nauc <- auc_wk4 |> \n  rename(week_4 = roc_auc) |> \n  mutate(week_26 = auc_wk26$roc_auc) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\nRows: 30\nColumns: 4\n$ repeat_num <chr> \"repeat1\", \"repeat1\", \"repeat1\", \"repeat1\", \"repeat1\", \"rep…\n$ fold_num   <chr> \"fold1\", \"fold2\", \"fold3\", \"fold4\", \"fold5\", \"fold6\", \"fold…\n$ week_4     <dbl> 0.5890269, 0.7058600, 0.6805259, 0.6269727, 0.7406656, 0.75…\n$ week_26    <dbl> 0.6405063, 0.6494382, 0.6066667, 0.5852641, 0.6827004, 0.63…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nauc_wk4 %>% \n  ggplot() + \n  geom_histogram(aes(x = roc_auc), bins = 10)\n```\n\n::: {.cell-output-display}\n![](ana_bayes_match_files/figure-html/auc_plots-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nauc_wk26 %>% \n  ggplot() + \n  geom_histogram(aes(x = roc_auc), bins = 10)\n```\n\n::: {.cell-output-display}\n![](ana_bayes_match_files/figure-html/auc_plots-2.png){width=672}\n:::\n:::\n\n\n### All models\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# from ?perf_mod()\n# Repeated CV (id = repeat, id2 = fold within repeat)\n\nset.seed(101)\npp <- auc |> \n  rename(id = repeat_num,\n         id2 = fold_num) |> \n  perf_mod(formula = statistic ~ model + (1 | id2/id), \n           # prior_intercept = rstanarm::student_t(autoscale = TRUE),\n           # prior = rstanarm::student_t(autoscale = TRUE),\n           transform = tidyposterior::logit_trans,  # for skewed & bounded AUC\n           iter = 2000, chains = 4,  \n           adapt_delta = .99,\n           # cores = 4, seed = 12345,\n           family = gaussian, \n  )  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 6.9e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.69 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 1.124 seconds (Warm-up)\nChain 1:                0.77 seconds (Sampling)\nChain 1:                1.894 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 3.9e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.39 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 1.02 seconds (Warm-up)\nChain 2:                0.542 seconds (Sampling)\nChain 2:                1.562 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 2.6e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.26 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 1.098 seconds (Warm-up)\nChain 3:                0.759 seconds (Sampling)\nChain 3:                1.857 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 2.5e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.892 seconds (Warm-up)\nChain 4:                0.76 seconds (Sampling)\nChain 4:                1.652 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nrstanarm::prior_summary(pp$stan)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\nPriors for model 'pp$stan' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 0.67, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 0.67, scale = 0.62)\n\nCoefficients\n  Specified prior:\n    ~ normal(location = 0, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 0, scale = 1.2)\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 4)\n\nCovariance\n ~ decov(reg. = 1, conc. = 1, shape = 1, scale = 1)\n------\nSee help('prior_summary.stanreg') for more details\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsummary(pp$stan)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      statistic ~ model + (1 | id2/id)\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 60\n groups:       id:id2 (30), id2 (10)\n\nEstimates:\n                                        mean   sd   10%   50%   90%\n(Intercept)                            0.6    0.0  0.5   0.6   0.6 \nmodelweek_4                            0.2    0.0  0.1   0.2   0.2 \nb[(Intercept) id:id2:repeat1:fold1]   -0.2    0.1 -0.3  -0.1   0.0 \nb[(Intercept) id:id2:repeat1:fold10]  -0.2    0.1 -0.3  -0.2   0.0 \nb[(Intercept) id:id2:repeat1:fold2]    0.1    0.1 -0.1   0.1   0.2 \nb[(Intercept) id:id2:repeat1:fold3]   -0.1    0.1 -0.2  -0.1   0.1 \nb[(Intercept) id:id2:repeat1:fold4]   -0.2    0.1 -0.3  -0.2   0.0 \nb[(Intercept) id:id2:repeat1:fold5]    0.2    0.1  0.0   0.2   0.3 \nb[(Intercept) id:id2:repeat1:fold6]    0.1    0.1  0.0   0.1   0.2 \nb[(Intercept) id:id2:repeat1:fold7]    0.1    0.1  0.0   0.1   0.3 \nb[(Intercept) id:id2:repeat1:fold8]    0.1    0.1  0.0   0.1   0.2 \nb[(Intercept) id:id2:repeat1:fold9]   -0.1    0.1 -0.2  -0.1   0.0 \nb[(Intercept) id:id2:repeat2:fold1]    0.1    0.1  0.0   0.1   0.2 \nb[(Intercept) id:id2:repeat2:fold10]   0.2    0.1  0.1   0.2   0.3 \nb[(Intercept) id:id2:repeat2:fold2]   -0.1    0.1 -0.2  -0.1   0.0 \nb[(Intercept) id:id2:repeat2:fold3]   -0.3    0.1 -0.5  -0.3  -0.2 \nb[(Intercept) id:id2:repeat2:fold4]    0.1    0.1 -0.1   0.1   0.2 \nb[(Intercept) id:id2:repeat2:fold5]    0.1    0.1  0.0   0.1   0.2 \nb[(Intercept) id:id2:repeat2:fold6]    0.2    0.1  0.1   0.2   0.4 \nb[(Intercept) id:id2:repeat2:fold7]    0.0    0.1 -0.2   0.0   0.1 \nb[(Intercept) id:id2:repeat2:fold8]   -0.1    0.1 -0.2  -0.1   0.1 \nb[(Intercept) id:id2:repeat2:fold9]    0.0    0.1 -0.1   0.0   0.1 \nb[(Intercept) id:id2:repeat3:fold1]    0.0    0.1 -0.1   0.0   0.1 \nb[(Intercept) id:id2:repeat3:fold10]   0.0    0.1 -0.1   0.0   0.1 \nb[(Intercept) id:id2:repeat3:fold2]   -0.2    0.1 -0.3  -0.2  -0.1 \nb[(Intercept) id:id2:repeat3:fold3]    0.3    0.1  0.2   0.3   0.4 \nb[(Intercept) id:id2:repeat3:fold4]    0.0    0.1 -0.1   0.0   0.1 \nb[(Intercept) id:id2:repeat3:fold5]   -0.1    0.1 -0.2  -0.1   0.1 \nb[(Intercept) id:id2:repeat3:fold6]    0.1    0.1  0.0   0.1   0.2 \nb[(Intercept) id:id2:repeat3:fold7]   -0.1    0.1 -0.2  -0.1   0.0 \nb[(Intercept) id:id2:repeat3:fold8]   -0.3    0.1 -0.4  -0.3  -0.2 \nb[(Intercept) id:id2:repeat3:fold9]    0.2    0.1  0.0   0.2   0.3 \nb[(Intercept) id2:fold1]               0.0    0.0 -0.1   0.0   0.0 \nb[(Intercept) id2:fold10]              0.0    0.0  0.0   0.0   0.1 \nb[(Intercept) id2:fold2]               0.0    0.1 -0.1   0.0   0.0 \nb[(Intercept) id2:fold3]               0.0    0.0 -0.1   0.0   0.0 \nb[(Intercept) id2:fold4]               0.0    0.1 -0.1   0.0   0.0 \nb[(Intercept) id2:fold5]               0.0    0.1  0.0   0.0   0.1 \nb[(Intercept) id2:fold6]               0.0    0.1  0.0   0.0   0.1 \nb[(Intercept) id2:fold7]               0.0    0.0 -0.1   0.0   0.1 \nb[(Intercept) id2:fold8]               0.0    0.1 -0.1   0.0   0.0 \nb[(Intercept) id2:fold9]               0.0    0.0  0.0   0.0   0.1 \nsigma                                  0.1    0.0  0.1   0.1   0.2 \nSigma[id:id2:(Intercept),(Intercept)]  0.0    0.0  0.0   0.0   0.1 \nSigma[id2:(Intercept),(Intercept)]     0.0    0.0  0.0   0.0   0.0 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 0.7    0.0  0.6   0.7   0.7  \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                                      mcse Rhat n_eff\n(Intercept)                           0.0  1.0  1744 \nmodelweek_4                           0.0  1.0  5472 \nb[(Intercept) id:id2:repeat1:fold1]   0.0  1.0  2816 \nb[(Intercept) id:id2:repeat1:fold10]  0.0  1.0  3332 \nb[(Intercept) id:id2:repeat1:fold2]   0.0  1.0  3796 \nb[(Intercept) id:id2:repeat1:fold3]   0.0  1.0  3909 \nb[(Intercept) id:id2:repeat1:fold4]   0.0  1.0  3096 \nb[(Intercept) id:id2:repeat1:fold5]   0.0  1.0  3222 \nb[(Intercept) id:id2:repeat1:fold6]   0.0  1.0  2599 \nb[(Intercept) id:id2:repeat1:fold7]   0.0  1.0  3658 \nb[(Intercept) id:id2:repeat1:fold8]   0.0  1.0  3637 \nb[(Intercept) id:id2:repeat1:fold9]   0.0  1.0  3671 \nb[(Intercept) id:id2:repeat2:fold1]   0.0  1.0  3743 \nb[(Intercept) id:id2:repeat2:fold10]  0.0  1.0  3621 \nb[(Intercept) id:id2:repeat2:fold2]   0.0  1.0  3453 \nb[(Intercept) id:id2:repeat2:fold3]   0.0  1.0  2155 \nb[(Intercept) id:id2:repeat2:fold4]   0.0  1.0  3570 \nb[(Intercept) id:id2:repeat2:fold5]   0.0  1.0  3692 \nb[(Intercept) id:id2:repeat2:fold6]   0.0  1.0  2450 \nb[(Intercept) id:id2:repeat2:fold7]   0.0  1.0  4239 \nb[(Intercept) id:id2:repeat2:fold8]   0.0  1.0  3794 \nb[(Intercept) id:id2:repeat2:fold9]   0.0  1.0  3885 \nb[(Intercept) id:id2:repeat3:fold1]   0.0  1.0  3940 \nb[(Intercept) id:id2:repeat3:fold10]  0.0  1.0  4226 \nb[(Intercept) id:id2:repeat3:fold2]   0.0  1.0  2898 \nb[(Intercept) id:id2:repeat3:fold3]   0.0  1.0  2486 \nb[(Intercept) id:id2:repeat3:fold4]   0.0  1.0  3709 \nb[(Intercept) id:id2:repeat3:fold5]   0.0  1.0  3703 \nb[(Intercept) id:id2:repeat3:fold6]   0.0  1.0  2651 \nb[(Intercept) id:id2:repeat3:fold7]   0.0  1.0  3702 \nb[(Intercept) id:id2:repeat3:fold8]   0.0  1.0  2424 \nb[(Intercept) id:id2:repeat3:fold9]   0.0  1.0  3719 \nb[(Intercept) id2:fold1]              0.0  1.0  2816 \nb[(Intercept) id2:fold10]             0.0  1.0  3493 \nb[(Intercept) id2:fold2]              0.0  1.0  2477 \nb[(Intercept) id2:fold3]              0.0  1.0  3099 \nb[(Intercept) id2:fold4]              0.0  1.0  3149 \nb[(Intercept) id2:fold5]              0.0  1.0  2393 \nb[(Intercept) id2:fold6]              0.0  1.0  1462 \nb[(Intercept) id2:fold7]              0.0  1.0  3453 \nb[(Intercept) id2:fold8]              0.0  1.0  2350 \nb[(Intercept) id2:fold9]              0.0  1.0  3316 \nsigma                                 0.0  1.0  1282 \nSigma[id:id2:(Intercept),(Intercept)] 0.0  1.0  1372 \nSigma[id2:(Intercept),(Intercept)]    0.0  1.0  1348 \nmean_PPD                              0.0  1.0  4304 \nlog-posterior                         0.3  1.0   739 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# shinystan::launch_shinystan(pp$stan)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp %>%  write_rds(file.path(path_models, \n                            str_c(\"posteriors_\", version, \"_nested.rds\")))\n```\n:::\n\n\n### Model posterier CIs\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_tidy <- pp %>% \n  tidy(seed = 123)\n\nq = c(.025, .5, .975)\npp_tidy |> \n  group_by(model) |> \n  summarize(median = quantile(posterior, probs = q[2]),\n            lower = quantile(posterior, probs = q[1]), \n            upper = quantile(posterior, probs = q[3])) |> \n  mutate(model = factor(model, levels = c(\"week_26\", \"week_4\"),\n                        labels = c(\"Week 26\", \"Week 4\")),\n         y = 1000) |> \n  arrange(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\n# A tibble: 2 × 5\n  model   median lower upper     y\n  <fct>    <dbl> <dbl> <dbl> <dbl>\n1 Week 26  0.640 0.619 0.661  1000\n2 Week 4   0.684 0.665 0.703  1000\n```\n\n\n:::\n:::\n\n\n### Model contrasts\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_contrasts <- contrast_models(pp, \n                                list(\"week_4\"), \n                                list(\"week_26\"))\nsummary(pp_contrasts, size = .01, prob = 0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\n# A tibble: 1 × 9\n  contrast          probability   mean  lower  upper  size pract_neg pract_equiv\n  <chr>                   <dbl>  <dbl>  <dbl>  <dbl> <dbl>     <dbl>       <dbl>\n1 week_4 vs week_26           1 0.0439 0.0275 0.0601  0.01         0     0.00075\n  pract_pos\n      <dbl>\n1     0.999\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\npp_contrasts |> autoplot(size = .01)\n```\n\n::: {.cell-output-display}\n![](ana_bayes_match_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nHere are contrasts against 0 rather than using ROPE\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_contrasts |> \n  mutate(wk4_gt_wk26 = if_else(difference > 0, 1, 0)) |>\n  pull(wk4_gt_wk26) |> \n  mean()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\n[1] 1\n```\n\n\n:::\n:::\n\n\n### Plots\n\nModel posteriors\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nci <- pp_tidy |> \n  summary() |> \n  mutate(model = factor(model, levels = c(\"week_4\", \"week_26\")),\n         y = 1000) \n```\n:::\n\n::: {#cell-fig-posteriors .cell}\n\n```{.r .cell-code .hidden}\nfig_posteriors <- pp_tidy |> \n  mutate(model = factor(model, levels = c(\"week_4\", \"week_26\"))) |> \n  ggplot() + \n  geom_histogram(aes(x = posterior, fill = model), color = \"black\", alpha = .4, \n                 bins = 30) +\n  geom_segment(mapping = aes(y = y + 100, yend = y - 100, x = mean, xend = mean,\n                             color = model),\n               data = ci) +\n  geom_segment(mapping = aes(y = y, yend = y, x = lower, xend = upper, color = model),\n               data = ci) +\n  facet_wrap(~model, ncol = 1) +\n  scale_y_continuous(\"Posterior Probability\", breaks = c(0, 500, 1000)) +\n  # ylab(\"Posterior Probability Density\") +\n  xlab(\"Area Under ROC Curve\")\n\nfig_posteriors\n```\n\n::: {.cell-output-display}\n![](ana_bayes_match_files/figure-html/fig-posteriors-1.png){#fig-posteriors width=672}\n:::\n:::\n\n\nmodel contrast posteriors\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nci_con <- pp |>\n  contrast_models(list(\"week_4\"), \n                  list(\"week_26\")) |> \n  summary(size = .01) |> \n  mutate(contrast = factor(contrast, \n                           levels = c(\"week_4 vs week_26\"),\n                           labels = c(\"week 4 vs. week 26\")),\n         y = 700)\n```\n:::\n\n::: {#cell-fig-contrasts .cell}\n\n```{.r .cell-code .hidden}\nfig_contrasts <- pp |> \n  tidy(seed = 123) |>   \n  group_by(model) |> \n  mutate(sample = row_number()) |> \n  ungroup() |> \n  pivot_wider(names_from = model, values_from = posterior) |> \n  mutate(posterior = week_4 - week_26) |> \n  ggplot() +\n  geom_histogram(aes(x = posterior), \n                 color = \"black\", alpha = .4, bins = 30) +\n  geom_vline(xintercept = -.01, color = \"yellow\", linetype = \"dashed\", linewidth = 1) +\n  geom_vline(xintercept = .01, color = \"yellow\", linetype = \"dashed\", linewidth = 1) +\n  geom_segment(mapping = aes(y = y+50, yend = y-50, x = mean, xend = mean), \n               data = ci_con) +\n  geom_segment(mapping = aes(y = y, yend = y, x = lower, xend = upper), \n               data = ci_con) +\n  ylab(\"Posterior Probability\") +\n  xlab(\"Model Contrast for auROC (Week 4 vs. Week 26)\")\n\nfig_contrasts\n```\n\n::: {.cell-output-display}\n![](ana_bayes_match_files/figure-html/fig-contrasts-1.png){#fig-contrasts width=672}\n:::\n:::\n",
    "supporting": [
      "ana_bayes_match_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}