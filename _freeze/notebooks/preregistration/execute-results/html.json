{
  "hash": "bb9a730f6d99c951f3a8d1834838244f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Preregistration: Evaluation of Clinical Benefit\"\nauthor: \"Gaylen Fronk\"\ndate: \"2024-04-23\"\noutput: \n  html_document:\n    toc: true \n    toc_depth: 4\nparams:\n  study: \"match\"\n  version: \"v5\"\n  algorithms: \"all\"   # \"all\" or name of specific algorithm\nformat:\n  html:\n    embed-resources: true\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\nstudy <- params$study\nversion <- params$version\nalgorithms <- params$algorithms\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n#| echo: false\n\n# packages for script\nlibrary(lme4)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: Matrix\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n#| echo: false\n\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n✔ broom        1.0.5     ✔ recipes      1.0.9\n✔ dials        1.2.0     ✔ rsample      1.2.0\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.4.4     ✔ tidyr        1.3.1\n✔ infer        1.0.6     ✔ tune         1.1.2\n✔ modeldata    1.3.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.3.0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()  masks scales::discard()\n✖ tidyr::expand()   masks Matrix::expand()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ tidyr::pack()     masks Matrix::pack()\n✖ recipes::step()   masks stats::step()\n✖ tidyr::unpack()   masks Matrix::unpack()\n✖ recipes::update() masks Matrix::update(), stats::update()\n• Learn how to get started at https://www.tidymodels.org/start/\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n#| echo: false\n\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ lubridate 1.9.3     ✔ stringr   1.5.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ readr::spec()       masks yardstick::spec()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n#| echo: false\n\nlibrary(blme)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: package 'blme' was built under R version 4.3.3\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n#| echo: false\n\nlibrary(parallel)\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"c045eee2655a18dc85e715b78182f176327358a7\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n#| echo: false\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/chtc/static_files/fun_chtc.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"bb7bddab14e337e74cb65ad3b94d58a2492d34cd\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n#| echo: false\n\ntheme_set(theme_classic()) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n#| echo: false\n\n# handle conflicts\noptions(conflicts.policy = \"depends.ok\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n\n# absolute paths\nswitch (Sys.info()[['sysname']],\n        # PC paths\n        Windows = {\n          path_models <- \"P:/studydata/match/models\"},\n        \n        # IOS paths\n        Darwin = {\n          path_models <- \"/Volumes/private/studydata/match/models\"},\n        \n        # Linux paths\n        Linux = {\n          path_models <- \"~/mnt/private/studydata/match/models\"}\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n\n# chunk defaults\nknitr::opts_chunk$set(attr.output='style=\"max-height: 500px;\"')\n\noptions(tibble.width = Inf)\noptions(tibble.print_max = Inf)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n\n# read in d for week 4 model\nd_wk4 <- read_csv(file.path(path_models, \"pp_hybrid_wk4_outcome\", \n                        str_c(\"aim_2_\", version, \"_pp_hybrid_wk4_outcome.csv\")),\n              show_col_types = FALSE) |> \n  mutate(outcome_rct_wk4_num = if_else(outcome_rct_wk4 == \"abstinent\", 1, 0),\n         outcome_rct_wk12_num = if_else(outcome_rct_wk12 == \"abstinent\", 1, 0),\n         outcome_rct_wk26_num = if_else(outcome_rct_wk26 == \"abstinent\", 1, 0),\n         tx_worst = case_when(\n           prob_patch < prob_combo_nrt & prob_patch < prob_varenicline ~ \"patch\",\n           prob_combo_nrt < prob_patch & prob_combo_nrt < prob_varenicline ~ \"combo_nrt\",\n           prob_varenicline < prob_patch & prob_varenicline < prob_combo_nrt ~ \"varenicline\",\n           TRUE ~ NA_character_),\n         tx_second = case_when(\n           tx_worst == \"patch\" & tx_best == \"varenicline\" ~ \"combo_nrt\",\n           tx_worst == \"patch\" & tx_best == \"combo_nrt\" ~ \"varenicline\",\n           tx_worst == \"varenicline\" & tx_best == \"patch\" ~ \"combo_nrt\",\n           tx_worst == \"varenicline\" & tx_best == \"combo_nrt\" ~ \"patch\",\n           tx_worst == \"combo_nrt\" & tx_best == \"varenicline\" ~ \"patch\",\n           tx_worst == \"combo_nrt\" & tx_best == \"patch\" ~ \"varenicline\",\n           TRUE ~ NA_character_)) |> \n  mutate(tx_rank = case_when(\n    tx_rct == tx_best ~ \"first\",\n    tx_rct == tx_second ~ \"second\",\n    tx_rct == tx_worst ~ \"third\",\n    TRUE ~ NA_character_)) |> \n  select(subid, starts_with(\"tx_\"), starts_with(\"prob_\"),\n         outcome_rct_wk4_num, outcome_rct_wk12_num, outcome_rct_wk26_num) \n\n# read in best_config for week 4 model\nbest_configuration_wk4 <- read_csv(file.path(path_models, \"pp_hybrid_wk4_outcome\",\n                                         str_c(\"best_config_\", version, \".csv\")),\n                               show_col_types = FALSE) |> \n  select(algorithm, feature_set, alpha = hp1, lambda = hp2, resample)\n\n# read in d for week 26 model\n# d_wk26 <- read_csv(file.path(path_models, \"pp_hybrid_wk26_outcome\", \n#                         str_c(\"aim_2_\", version, \"_pp_hybrid_wk26_outcome.csv\")),\n#               show_col_types = FALSE) |> \n#   mutate(outcome_rct_wk4_num = if_else(outcome_rct_wk4 == \"abstinent\", 1, 0),\n#          outcome_rct_wk12_num = if_else(outcome_rct_wk12 == \"abstinent\", 1, 0),\n#          outcome_rct_wk26_num = if_else(outcome_rct_wk26 == \"abstinent\", 1, 0),\n#          tx_worst = case_when(\n#            prob_patch < prob_combo_nrt & prob_patch < prob_varenicline ~ \"patch\",\n#            prob_combo_nrt < prob_patch & prob_combo_nrt < prob_varenicline ~ \"combo_nrt\",\n#            prob_varenicline < prob_patch & prob_varenicline < prob_combo_nrt ~ \"varenicline\",\n#            TRUE ~ NA_character_),\n#          tx_second = case_when(\n#            tx_worst == \"patch\" & tx_best == \"varenicline\" ~ \"combo_nrt\",\n#            tx_worst == \"patch\" & tx_best == \"combo_nrt\" ~ \"varenicline\",\n#            tx_worst == \"varenicline\" & tx_best == \"patch\" ~ \"combo_nrt\",\n#            tx_worst == \"varenicline\" & tx_best == \"combo_nrt\" ~ \"patch\",\n#            tx_worst == \"combo_nrt\" & tx_best == \"varenicline\" ~ \"patch\",\n#            tx_worst == \"combo_nrt\" & tx_best == \"patch\" ~ \"varenicline\",\n#            TRUE ~ NA_character_)) |> \n#   mutate(tx_rank = case_when(\n#     tx_rct == tx_best ~ \"first\",\n#     tx_rct == tx_second ~ \"second\",\n#     tx_rct == tx_worst ~ \"third\",\n#     TRUE ~ NA_character_)) |> \n#   select(subid, starts_with(\"tx_\"), starts_with(\"prob_\"),\n#          outcome_rct_wk4_num, outcome_rct_wk12_num, outcome_rct_wk26_num) \n\n# read in best_config for week 26 model\nbest_configuration_wk26 <- read_csv(file.path(path_models, \"pp_hybrid_wk26_outcome\",\n                                         str_c(\"best_config_\", version, \".csv\")),\n                               show_col_types = FALSE) |> \n  select(algorithm, feature_set, learning_rate = hp1, tree_depth = hp2, \n         mtry = hp3, resample)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n#| eval: false\n\n# make figure for john's presentation\nd_fig <- d_wk4 |> \n  select(subid, tx_rank, \n         outcome_rct_wk4_num, outcome_rct_wk12_num, outcome_rct_wk26_num) |> \n  pivot_longer(\n    cols = c(outcome_rct_wk4_num, outcome_rct_wk12_num, outcome_rct_wk26_num),\n    names_to = \"week\",\n    names_pattern = \"(?<=outcome_rct_)(.+)(?=_num)\",\n    values_to = \"outcome_rct_num\"\n  ) |> \n  mutate(tx_rank = factor(tx_rank, \n                          levels = c(\"first\", \"second\", \"third\")),\n         week = factor(week,\n                       levels = c(\"wk4\", \"wk12\", \"wk26\")),\n         subid = factor(subid)) |> \n  summarize(outcome_mean = mean(outcome_rct_num), .by = c(tx_rank, week)) \n\n# bar chart\nd_fig |> \n  ggplot(aes(x = week, y = outcome_mean, fill = tx_rank)) +\n  geom_col(position = \"dodge\") \n```\n:::\n\n\n## Study Overview\n\n### Specific Aims\n\nThis project represents a tangible application of the precision mental health paradigm using modern machine learning approaches. This project aims to produce a decision-making tool to select among cigarette smoking cessation treatments for individuals looking to quit smoking. \n\nCigarette smoking remains a critical and costly public health crisis. Existing treatments are only modestly effective at best. Additionally, treatments are similarly effective at the population level, meaning that even population-level effectiveness cannot guide treatment selection for individuals quitting smoking. Thus, deciding among first-line (i.e., FDA-approved) smoking cessation medications is a specific, objective decision that many individuals who smoke (or their providers) must make. Successful application of the precision mental health paradigm to cigarette smoking cessation would have immediate clinical benefit. \n\nSpecifically, this project pursues the following aims:\n\n**AIM 1: Build a machine learning model to guide treatment selection for cigarette smoking cessation.** We will build a machine learning model to predict treatment success (i.e., point-prevalence abstinence from smoking) for people who smoke who received one of three cigarette smoking cessation treatments. This model will use clinical features (predictors) from a richly characterized sample of people who smoke from a previously completed randomized controlled trial. The model will produce probabilities of treatment success for each treatment such that it can guide selection of the best treatment for any specific individual.\n\n**AIM 2: Evaluate the clinical benefit of using a treatment selection machine learning model.** Using the best model identified in **AIM 1**, we will identify the treatment for each person that gives them the highest likelihood of abstinence by comparing predicted probabilities of abstinence for each participant for each treatment. We will then evaluate the clinical benefit of this model-based treatment selection approach. \n\n### Data\n\nThis project relies on existing data from a completed comparative effectiveness trial by [Baker et al., 2016](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4824537/). Briefly, 1086 individuals who smoke cigarettes were randomized to receive varenicline, combination nicotine replacement therapy (NRT), or nicotine patch to assist with a quit attempt. Individuals were richly characterized at baseline (pre-treatment) with respect to demographic characteristics, mental health, social/environmental variables, physical health, and smoking history. Participants were assessed periodically for biologically confirmed, 7-day point-prevalence abstinence. When abstinence was biologically confirmed (i.e., via exhaled carbon monoxide), individuals were labeled as abstinent; otherwise, individuals were labeled as smoking.\n\n## Analysis Progress at Time of Preregistration\n\n### Completed: Model Building, Selection, & Evaluation\n\n**AIM 1** analyses have been completed: Models using all available data have been fit and selected with nested cross-validation (1 repeat of 10-fold cross-validation in the inner loops, 3 repeats of 10-fold cross-validation in the outer loop). These 30-held out folds (\"test sets\") were used to evaluate model performance.\n\nModels have been fit using two outcomes:\n\n* Week 4 7-day point-prevalance abstinence\n\n* Week 26 (60 month) 7-day point-prevalence abstinence\n\nA single, best model for each outcome was selected with 1 repeat of 10-fold cross-validation in the full dataset. \n\nThe best model configuration for the **Week 4 outcome** includes the following:\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\nglimpse(best_configuration_wk4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\nRows: 1\nColumns: 5\n$ algorithm   <chr> \"glmnet\"\n$ feature_set <chr> \"item_ordinal\"\n$ alpha       <dbl> 0.1\n$ lambda      <dbl> 0.1326421\n$ resample    <chr> \"up_1\"\n```\n\n\n:::\n:::\n\n\n* Selected algorithm was glmnet (xgboost and random forest also considered)\n\n* Selected feature set was \"item_ordinal\" indicating that individual items (rather than scale scores) were used, and ordinal scoring was used for ordered data (rather than dummy coding)\n\n* Selected resampling approach was \"up_1\" corresponding to upsampling (vs. downsampling or SMOTE) with a ratio of 1:1 (majority:minority class)\n\n* Values of the hyperparameters alpha and lambda were selected from sensible ranges for each value\n\nThe best model configuration for the **Week 26 outcome** includes the following:\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\nglimpse(best_configuration_wk26)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\nRows: 1\nColumns: 6\n$ algorithm     <chr> \"xgboost\"\n$ feature_set   <chr> \"item_knn_5\"\n$ learning_rate <dbl> 0.01\n$ tree_depth    <dbl> 3\n$ mtry          <dbl> 50\n$ resample      <chr> \"up_1\"\n```\n\n\n:::\n:::\n\n\n* Selected algorithm was UPDATE (xgboost and random forest also considered)\n\n* Selected feature set was \"UPDATE\" indicating that individual items (rather than scale scores) were used, and ordinal scoring was used for ordered data (rather than dummy coding)\n\n* Selected resampling approach was \"UPDATE\" corresponding to upsampling (vs. downsampling or SMOTE) with a ratio of 1:1 (majority:minority class)\n\n* Values of the hyperparameters UPDATE were selected from sensible ranges for each value\n\n### Completed: Model Performance\n\nModels were evaluated using our primary performance metric, area under the ROC curve (auROC), an index of how well our models discriminate between positive (abstinent) and negative (smoking) cases. \n\nWe evaluated model performance in-depth by conducting *Bayesian hierarchical generalized linear models* to estimate the posterior probability distributions and 95% Bayesian credible intervals (CIs) for auROC for our best models from the 30 held-out test sets from nested cross-validation. Below, you can see the posterior probabilities for auROC for our week 4 (top panel) and week 26 (bottom panel) models.\n\n\n{{< embed ana_bayes_match.qmd#fig-posteriors >}}\n\n\n\nThe horizontal line indicates the 95% CIs. The vertical line represents the median posterior probability for auROC. This represents our best estimate for the magnitude of the auROC parameter for each model. These CIs do not contain 0.5 (i.e., chance performance), suggesting both models are capturing signal in the data.\n\n*Because both models have predictive value as evidenced by these Bayesian analyses, we will conduct AIM 2 analyses with both models.*\n\n### In Progress: AIM 2 Clinical Benefit Analyses\n\n**AIM 2** analyses using this full model are underway. Here, we walk through our process using the data for only the week 4 model; however, the data structure and process are identical for the week 26 model.\n\nWe have used the final models (for each outcome) fit in the full dataset to generate three predictions (probabilities, `prob_*`) for each participant by substituting each treatment into the model inputs. Thus, there is one prediction per person per treatment. \n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nset.seed(82294)\nd_wk4 |> \n  select(subid, prob_patch, prob_combo_nrt, prob_varenicline) |> \n  slice_sample(n = 8) |> \n  print_kbl(digits = 3)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div style=\"border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:500px; overflow-x: scroll; width:100%; \"><table class=\"table table-striped table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> subid </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> prob_patch </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> prob_combo_nrt </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> prob_varenicline </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 40244 </td>\n   <td style=\"text-align:right;\"> 0.430 </td>\n   <td style=\"text-align:right;\"> 0.531 </td>\n   <td style=\"text-align:right;\"> 0.570 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 51235 </td>\n   <td style=\"text-align:right;\"> 0.189 </td>\n   <td style=\"text-align:right;\"> 0.198 </td>\n   <td style=\"text-align:right;\"> 0.159 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 50478 </td>\n   <td style=\"text-align:right;\"> 0.436 </td>\n   <td style=\"text-align:right;\"> 0.319 </td>\n   <td style=\"text-align:right;\"> 0.403 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 40482 </td>\n   <td style=\"text-align:right;\"> 0.247 </td>\n   <td style=\"text-align:right;\"> 0.222 </td>\n   <td style=\"text-align:right;\"> 0.257 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 30048 </td>\n   <td style=\"text-align:right;\"> 0.583 </td>\n   <td style=\"text-align:right;\"> 0.542 </td>\n   <td style=\"text-align:right;\"> 0.561 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 30294 </td>\n   <td style=\"text-align:right;\"> 0.339 </td>\n   <td style=\"text-align:right;\"> 0.315 </td>\n   <td style=\"text-align:right;\"> 0.340 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 31221 </td>\n   <td style=\"text-align:right;\"> 0.192 </td>\n   <td style=\"text-align:right;\"> 0.153 </td>\n   <td style=\"text-align:right;\"> 0.217 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 50676 </td>\n   <td style=\"text-align:right;\"> 0.148 </td>\n   <td style=\"text-align:right;\"> 0.169 </td>\n   <td style=\"text-align:right;\"> 0.140 </td>\n  </tr>\n</tbody>\n</table></div>\n\n`````\n:::\n:::\n\n\nThe treatment that yields the highest model-predicted probability of abstinence is identified as that participant's \"best\" treatment (`tx_best`). \n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nd_wk4 |> \n  select(subid, tx_best, prob_patch, prob_combo_nrt, prob_varenicline) |> \n  slice_sample(n = 8) |> \n  print_kbl(digits = 3)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div style=\"border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:500px; overflow-x: scroll; width:100%; \"><table class=\"table table-striped table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> subid </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> tx_best </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> prob_patch </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> prob_combo_nrt </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> prob_varenicline </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 50666 </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n   <td style=\"text-align:right;\"> 0.159 </td>\n   <td style=\"text-align:right;\"> 0.185 </td>\n   <td style=\"text-align:right;\"> 0.189 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 50224 </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n   <td style=\"text-align:right;\"> 0.193 </td>\n   <td style=\"text-align:right;\"> 0.165 </td>\n   <td style=\"text-align:right;\"> 0.207 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 50422 </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n   <td style=\"text-align:right;\"> 0.344 </td>\n   <td style=\"text-align:right;\"> 0.352 </td>\n   <td style=\"text-align:right;\"> 0.246 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 30984 </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n   <td style=\"text-align:right;\"> 0.195 </td>\n   <td style=\"text-align:right;\"> 0.227 </td>\n   <td style=\"text-align:right;\"> 0.197 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 50295 </td>\n   <td style=\"text-align:right;\"> patch </td>\n   <td style=\"text-align:right;\"> 0.455 </td>\n   <td style=\"text-align:right;\"> 0.431 </td>\n   <td style=\"text-align:right;\"> 0.437 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 20769 </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n   <td style=\"text-align:right;\"> 0.450 </td>\n   <td style=\"text-align:right;\"> 0.516 </td>\n   <td style=\"text-align:right;\"> 0.569 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 51261 </td>\n   <td style=\"text-align:right;\"> patch </td>\n   <td style=\"text-align:right;\"> 0.357 </td>\n   <td style=\"text-align:right;\"> 0.340 </td>\n   <td style=\"text-align:right;\"> 0.305 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 30149 </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n   <td style=\"text-align:right;\"> 0.443 </td>\n   <td style=\"text-align:right;\"> 0.465 </td>\n   <td style=\"text-align:right;\"> 0.341 </td>\n  </tr>\n</tbody>\n</table></div>\n\n`````\n:::\n:::\n\n\nThe best treatments spanned all three medication options: varenicline, combination nicotine replacement therapy (\"combo_nrt\"), and nicotine patch (\"patch\").\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nd_wk4 |> \n  tab(tx_best)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\n# A tibble: 3 × 3\n  tx_best         n  prop\n  <chr>       <int> <dbl>\n1 combo_nrt     339 0.312\n2 patch         193 0.178\n3 varenicline   554 0.510\n```\n\n\n:::\n:::\n\n\nSome participants' best treatment (`tx_best`) matched what they were randomly assigned in the original trial (`tx_rct`). Other participants may have received what the model identified as their second-best or worst treatment. Thus, participants' RCT-assigned treatment can be categorized by whether it \"matched\" their model-assigned treatment (`tx_match`).\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nd_wk4 |> \n  select(subid, tx_match, tx_rct, tx_best, tx_second, tx_worst) |> \n  slice_sample(n = 10) |> \n  print_kbl()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div style=\"border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:500px; overflow-x: scroll; width:100%; \"><table class=\"table table-striped table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> subid </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> tx_match </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> tx_rct </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> tx_best </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> tx_second </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> tx_worst </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 40645 </td>\n   <td style=\"text-align:right;\"> TRUE </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n   <td style=\"text-align:right;\"> patch </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 20015 </td>\n   <td style=\"text-align:right;\"> FALSE </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n   <td style=\"text-align:right;\"> patch </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 40126 </td>\n   <td style=\"text-align:right;\"> TRUE </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n   <td style=\"text-align:right;\"> patch </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 51165 </td>\n   <td style=\"text-align:right;\"> TRUE </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n   <td style=\"text-align:right;\"> patch </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 30705 </td>\n   <td style=\"text-align:right;\"> FALSE </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n   <td style=\"text-align:right;\"> patch </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 30179 </td>\n   <td style=\"text-align:right;\"> TRUE </td>\n   <td style=\"text-align:right;\"> patch </td>\n   <td style=\"text-align:right;\"> patch </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 51390 </td>\n   <td style=\"text-align:right;\"> TRUE </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n   <td style=\"text-align:right;\"> patch </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 51817 </td>\n   <td style=\"text-align:right;\"> FALSE </td>\n   <td style=\"text-align:right;\"> patch </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n   <td style=\"text-align:right;\"> patch </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 50140 </td>\n   <td style=\"text-align:right;\"> FALSE </td>\n   <td style=\"text-align:right;\"> patch </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n   <td style=\"text-align:right;\"> patch </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 20359 </td>\n   <td style=\"text-align:right;\"> FALSE </td>\n   <td style=\"text-align:right;\"> patch </td>\n   <td style=\"text-align:right;\"> combo_nrt </td>\n   <td style=\"text-align:right;\"> patch </td>\n   <td style=\"text-align:right;\"> varenicline </td>\n  </tr>\n</tbody>\n</table></div>\n\n`````\n:::\n:::\n\n\nJust over one third of participants received their model-assigned \"best\" treatment in the original trial.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nd_wk4 |> \n  tab(tx_match)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\n# A tibble: 2 × 3\n  tx_match     n  prop\n  <lgl>    <int> <dbl>\n1 FALSE      677 0.623\n2 TRUE       409 0.377\n```\n\n\n:::\n:::\n\n\n## Purpose of Preregistration\n\nThe purpose of this document is to **preregister the analyses for evaluating the clinical benefit of this treatment selection model**. \n\nOur primary analysis will compare the observed outcomes (i.e., abstinence vs. smoking, from the original trial) for people who did or did not receive their best treatment. We will examine these outcomes over the following time points:\n\n* 4 weeks: This time point served as an outcome for a prediction model. This selection was made so that, in real-world implementation, treatment could be adjusted earlier for individuals for whom treatment is not working.\n\n* 12 weeks: This is end-of-treatment and represents a mid-point between the early (4-week) and later (26-week) outcomes.\n\n* 26 weeks (6 months): This time point served as an outcome for a prediction model. This is the gold standard assessment period for smoking cessation treatments and was the primary outcome for the original trial ([Baker et al., 2016](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4824537/)). This duration is often used as a proxy for long-term success.\n\nThus, our model will have the following components:\n\n1. Dependent variable: abstinence (vs. smoking; `outcome_rct_num`). Binary outcome with abstinence coded as 1 and smoking coded as 0.\n\n2. Independent variable: treatment match (`tx_match`). Between-subjects categorical variable with two levels (TRUE or FALSE). This variable will be coded with an orthogonal contrast such that we compare individuals who received their best treatment to individuals who did not.\n\n3. Independent variable: time (`week`). Within-subjects categorical variable with three levels (week 4, week 12, week 26). This variable will be coded with orthogonal Helmert contrasts to avoid making an assumption about the linearity of this effect. We will compare the earliest 4-week outcome to the two later outcomes, and the 12-week outcome to the 26-week (6 month) outcome. \n\n4. Interaction between treatment match and time\n\n5. Random slope for time (3 repeated observations of time for each subject)\n\n6. Random intercept\n\nWe plan to follow a mixed-effects modeling approach using the `lme4` package. Specifically, we will fit a generalized linear model using `glmer()` with the components listed above. \n\nOur **focal effect** is the effect of treatment match. We predict that individuals who received their best treatment will have improved outcomes compared to individuals who did not. \n\nOur **secondary effects** include: \n\n* The interactions between treatmennt match and both time contrasts (week 4 vs. later, week 12 vs. week 26). We do not have directional hypotheses about these interactions.\n\n  + If either of these interactions are significant (*p* < 0.05), we will conduct **follow-up tests** of the simple effect of the best vs. other treatment contrast at all 3 time points (week 4, week 12, and week 26).\n\nAlthough the above estimates comprise our focal effects, we plan to report the estimates, test statistics, *p*-values, and confidence intervals for all fixed effects from this model.\n\n## Shuffle Data\n\nTo ensure that all proposed analyses are feasible and to specify analyses as precisely as possible, the remainder of this document conducts analyses using our data with shuffled outcome variables. Following preregistration, our analyses will follow this script exactly using our real data.\n\n*Again, we will walk through this process using shuffled data from our week 4 model, but the process will be identical for our week 26 model.*\n\nTo create this shuffled dataset, we:\n\n* break the relationship between treatment match and outcome by sampling (without replacement) the treatment match variable (`tx_match`)\n\n* pivot into long format with week as a within-subjects factor\n\n* remove unnecessary variables\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nset.seed(72905)\nd_shuf <- d_wk4 |> \n  select(subid, tx_match, \n         outcome_rct_wk4_num, outcome_rct_wk12_num, outcome_rct_wk26_num) |> \n  mutate(tx_match = sample(d_wk4$tx_match, nrow(d_wk4), replace = FALSE)) |>\n  pivot_longer(\n    cols = c(outcome_rct_wk4_num, outcome_rct_wk12_num, outcome_rct_wk26_num),\n    names_to = \"week\",\n    names_pattern = \"(?<=outcome_rct_wk)(.+)(?=_num)\",\n    values_to = \"outcome_rct_num\"\n  ) |> \n  mutate(tx_match = factor(tx_match, \n                          levels = c(FALSE, TRUE)),\n         week = as.numeric(week)) |> \n  mutate(week_log = log(week)) |> \n  mutate(week_log_scale = scale(week_log)[,1])\n\nglimpse(d_shuf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\nRows: 3,258\nColumns: 6\n$ subid           <dbl> 20010, 20010, 20010, 20015, 20015, 20015, 20030, 20030…\n$ tx_match        <fct> TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ week            <dbl> 4, 12, 26, 4, 12, 26, 4, 12, 26, 4, 12, 26, 4, 12, 26,…\n$ outcome_rct_num <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, …\n$ week_log        <dbl> 1.386294, 2.484907, 3.258097, 1.386294, 2.484907, 3.25…\n$ week_log_scale  <dbl> -1.2890446, 0.1412207, 1.1478239, -1.2890446, 0.141220…\n```\n\n\n:::\n:::\n\n\nConfirm that data look random\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nd_shuf |> \n  group_by(week, tx_match) |> \n  summarize(mean_outcome = mean(outcome_rct_num)) \n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n`summarise()` has grouped output by 'week'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\n# A tibble: 6 × 3\n# Groups:   week [3]\n   week tx_match mean_outcome\n  <dbl> <fct>           <dbl>\n1     4 FALSE           0.349\n2     4 TRUE            0.330\n3    12 FALSE           0.290\n4    12 TRUE            0.291\n5    26 FALSE           0.244\n6    26 TRUE            0.252\n```\n\n\n:::\n:::\n\n\nSet contrasts for week and treatment match\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# contrast coding on week\n# c_week <- contr.helmert(c(\"wk26\", \"wk12\", \"wk4\"))\n# c_week[, 1] <- c_week[, 1] / (max(c_week[, 1]) - min(c_week[, 1]))\n# c_week[, 2] <- c_week[, 2] / (max(c_week[, 2]) - min(c_week[, 2]))\n# colnames(c_week) <- c(\"wk12_v_wk26\", \"wk4_v_later\")\n# contrasts(d_shuf$week) <- c_week\n# contrasts(d_shuf$week)\n\n# contrast coding on treatment match\nc_tx <- contr.helmert(c(FALSE, TRUE))\nc_tx[, 1] <- c_tx[, 1] / (max(c_tx[, 1]) - min(c_tx[, 1]))\ncolnames(c_tx) <- c(\"best_v_other\")\ncontrasts(d_shuf$tx_match) <- c_tx\ncontrasts(d_shuf$tx_match)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\n      best_v_other\nFALSE         -0.5\nTRUE           0.5\n```\n\n\n:::\n:::\n\n\n## Analysis Steps\n\n### Primary Model\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nmodel_1 <- glmer(outcome_rct_num ~ tx_match * week_log + (1 + week_log | subid),\n                       data = d_shuf,\n                       family = binomial(link = \"logit\"),\n                 control = glmerControl(optCtrl = list(maxfun = 3e6)))\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.0166072 (tol = 0.002, component 1)\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nsummary(model_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: outcome_rct_num ~ tx_match * week_log + (1 + week_log | subid)\n   Data: d_shuf\nControl: glmerControl(optCtrl = list(maxfun = 3e+06))\n\n     AIC      BIC   logLik deviance df.resid \n  3090.4   3133.1  -1538.2   3076.4     3251 \n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.28497 -0.42787 -0.06827  0.14552  1.45809 \n\nRandom effects:\n Groups Name        Variance Std.Dev. Corr \n subid  (Intercept) 10.58    3.253         \n        week_log    12.93    3.595    -1.00\nNumber of obs: 3258, groups:  subid, 1086\n\nFixed effects:\n                              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                     1.9798     0.3412   5.803 6.53e-09 ***\ntx_matchbest_v_other           -0.3267     0.3963  -0.824     0.41    \nweek_log                       -2.2200     0.2197 -10.103  < 2e-16 ***\ntx_matchbest_v_other:week_log   0.1215     0.2765   0.439     0.66    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) tx_m__ wek_lg\ntx_mtchbs__  0.138              \nweek_log    -0.932 -0.118       \ntx_mtch__:_ -0.104 -0.868  0.130\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.0166072 (tol = 0.002, component 1)\n```\n\n\n:::\n:::\n\n\n### Alternative Models for Robustness Checks\n\nThe model fit above has a singular fit. There are a number of recommended approaches to address singular fits (see `?isSingular`) if the model fit with our real data also has a singular fit. \n\nFor consistency, the following proposed alternative approaches mirror the steps we followed in a previously published project from our laboratory that also required complex mixed-effects modeling ([Schultz et al., 2022](https://psycnet.apa.org/record/2022-10249-001)). These steps are available in our open-access, annotated analysis scripts (e.g., [this script](https://osf.io/k8gfc)). \n\n1. Use a partially Bayesian method that uses regularizing priors to force the estimated random effects variance-covariance matrices away from singularity ([Chung et al., 2013](https://link.springer.com/article/10.1007/s11336-013-9328-2), `blme` package). We would use the `\"nlminbwrap\"` optimizer because `\"bobyqa\"` produced a singular fit.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nmodel_2 <- blme::bglmer(outcome_rct_num ~ tx_match * week_log + (1 + week_log | subid),\n                        data = d_shuf,\n                        family = binomial(link = \"logit\"),\n                        control = glmerControl(optCtrl = list(maxfun = 3e6)))\n```\n:::\n\n\n2. Use a simpler random effects structure to address problems with singular fits. Following this strategy, we would fit a model with only the random intercept.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nmodel_3 <- lme4::glmer(outcome_rct_num ~ tx_match * week + (1 | subid),\n                       data = d_shuf,\n                       family = binomial(link = \"logit\"),\n                       control = glmerControl(optimizer = \"bobyqa\",\n                                              optCtrl = list(maxfun = 3e6)))\n```\n:::\n\n\n3. Re-fit the glmer model with the full random effects structure across all available optimizers and review for consistency of log-likelihood ratios, fixed effects, and test statistics of focal effect across optimizers. \n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nopts <- tibble(optimizer = c(\"bobyqa\", \"Nelder_Mead\", \"nlminbwrap\", \n                             \"nmkbw\", \"optimx\", \"nloptwrap\", \"nloptwrap\"),\n               method = c(\"\", \"\", \"\", \"\", \"L-BFGS-B\", \n                          \"NLOPT_LN_NELDERMEAD\", \"NLOPT_LN_BOBYQA\")) %>% \n  as.data.frame()\n\nmodel_all <- allFit(model_1, verbose = FALSE, meth.tab = opts)\n```\n:::\n\n::: {.cell .hidden}\n\n```{.r .cell-code .hidden}\n#| include: false\n#| eval: false\n\n# Review warning/error messages across remaining optimizers\neffects <- tidy_opts(model_all, terms = \"tx_rankbest_v_other\")\nopt_names <- names(effects$msg)\neffects$msg |> \n  map2_dfr(opt_names, extract_opts_msgs)\n\n# confirm that log-likelihood ratios are equivalent across optimizers\neffects |> \n  filter(term == \"model\") |> \n  select(optimizer, llik)\n\n# Confirm fixed effects & test stats are equivalent across optimizers for our focal effect (best treatment vs. other)\neffects |> \n  filter(term == \"tx_rankbest_v_other\") |> \n  select(-msg, -llik)\n```\n:::\n\n\n### Follow-up analyses: Simple Effects\n\nIf either interaction for our secondary outcomes (best vs. other treatment rank contrast X both time contrasts) is significant (*p* < 0.05), we will conduct follow-up analyses to test the simple effect of the best vs. other treatment rank contrast at each time point.\n\nSimple effect at 4 weeks\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nd_4_shuf <- d_shuf |> \n  filter(week == \"wk4\")\n\nmodel_4wk <- glm(outcome_rct_num ~ tx_match, \n                 data = d_4_shuf,\n                 family = binomial(link = \"logit\"))\n\nsummary(model_4wk)\n```\n:::\n\n\nSimple effect at 12 weeks\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nd_12_shuf <- d_shuf |> \n  filter(week == \"wk12\")\n\nmodel_12wk <- glm(outcome_rct_num ~ tx_match, \n                  data = d_12_shuf,\n                  family = binomial(link = \"logit\"))\n\nsummary(model_12wk)\n```\n:::\n\n\nSimple effect at 26 weeks\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nd_26_shuf <- d_shuf |> \n  filter(week == \"wk26\")\n\nmodel_26wk <- glm(outcome_rct_num ~ tx_match, \n                  data = d_26_shuf,\n                  family = binomial(link = \"logit\"))\n\nsummary(model_26wk)\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}