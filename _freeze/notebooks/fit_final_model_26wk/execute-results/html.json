{
  "hash": "c90402f59059fca39adf8d9bfd581644",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Fits and characterizes final model for version v5 for outcome pp_hybrid_wk26_outcome\"\nauthor: \"Gaylen Fronk\"\ndate: \"2024-04-24\"\noutput: \n  html_document:\n    toc: true \n    toc_depth: 4\nparams:\n  study: \"match\"\n  version: \"v5\"\n  cv: \"kfold\"\n  algorithms: \"all\"   # \"all\" or name of specific algorithm\n  y_col_name: \"pp_hybrid_wk26_outcome\" \nformat:\n  html:\n    embed-resources: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n## Set Up Environment\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nstudy <- params$study\nversion <- params$version\ncv <- params$cv\nalgorithms <- params$algorithms\ny_col_name <- params$y_col_name\n```\n:::\n\n\nPackages for script\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n✔ broom        1.0.5     ✔ recipes      1.0.9\n✔ dials        1.2.0     ✔ rsample      1.2.0\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.4.4     ✔ tidyr        1.3.1\n✔ infer        1.0.6     ✔ tune         1.1.2\n✔ modeldata    1.3.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.3.0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ lubridate 1.9.3     ✔ stringr   1.5.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\nlibrary(Matrix)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\nlibrary(probably)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'probably'\n\nThe following objects are masked from 'package:base':\n\n    as.factor, as.ordered\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\nlibrary(here)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: package 'here' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nhere() starts at C:/Users/gfronk/Documents/GitHub/study_match\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"c045eee2655a18dc85e715b78182f176327358a7\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/chtc/static_files/fun_chtc.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"bb7bddab14e337e74cb65ad3b94d58a2492d34cd\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\ntheme_set(theme_classic()) \n```\n:::\n\n\nHandle conflicts\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\noptions(conflicts.policy = \"depends.ok\")\n```\n:::\n\n\nAbsolute paths\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nswitch (Sys.info()[['sysname']],\n        # PC paths\n        Windows = {\n          path_input <- stringr::str_c(\"P:/studydata/match/chtc/\", \n                                       y_col_name)\n          path_models <- stringr::str_c(\"P:/studydata/match/models/\", \n                                        y_col_name)},\n        \n        # IOS paths\n        Darwin = {\n          path_input <- stringr::str_c(\"/Volumes/private/studydata/match/chtc/\", \n                                       y_col_name)\n          path_models <- stringr::str_c(\"/Volumes/private/studydata/match/models/\", \n                                        y_col_name)},\n        \n        # Linux paths\n        Linux = {\n          path_input <- stringr::str_c(\"~/mnt/private/studydata/match/chtc/\", \n                                       y_col_name)\n          path_models <- stringr::str_c(\"~/mnt/private/studydata/match/models/\", \n                                        y_col_name)}\n)\n```\n:::\n\n\nChunk Defaults\n\n\n::: {.cell .hidden}\n\n```{.r .cell-code .hidden}\n#| include: false\n\nknitr::opts_chunk$set(attr.output='style=\"max-height: 500px;\"')\n\noptions(tibble.width = Inf)\noptions(tibble.print_max = Inf)\n```\n:::\n\n\n## Read in best configuration\n\nSelected in 1_metrics_inner (k-fold CV)\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nbest_config <- read_csv(file.path(path_models, \n                                  str_c(\"best_config_\", version, \".csv\")),\n                        show_col_types = FALSE)\n\nglimpse(best_config)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\nRows: 1\nColumns: 14\n$ n_jobs       <dbl> 10\n$ algorithm    <chr> \"xgboost\"\n$ feature_set  <chr> \"item_knn_5\"\n$ hp1          <dbl> 0.01\n$ hp2          <dbl> 3\n$ hp3          <dbl> 50\n$ resample     <chr> \"up_1\"\n$ accuracy     <dbl> 0.6697248\n$ bal_accuracy <dbl> 0.6315083\n$ roc_auc      <dbl> 0.6799157\n$ sens         <dbl> 0.5166667\n$ spec         <dbl> 0.7361362\n$ ppv          <dbl> 0.3514706\n$ npv          <dbl> 0.81173\n```\n\n\n:::\n:::\n\n\n## Fit best model in full dataset\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nbatch_names <- list.dirs(path_input, full.names = FALSE, recursive = FALSE) \n\nbatch_name <- batch_names[str_detect(batch_names, \"train\") & \n                            str_detect(batch_names, cv) &\n                            str_detect(batch_names, version) &\n                            str_detect(batch_names, best_config$algorithm)] \n\npath_batch <- file.path(path_input, batch_name)\nsource(file.path(path_batch, \"input\", \"training_controls.R\"))\n\nd <- read_csv(file.path(path_batch, \"input\", \"data_trn.csv\"), \n              show_col_types = FALSE) \n\nd_outcomes <- d |> \n  select(subid, ends_with(\"outcome\") & contains(\"hybrid\"))\n\nd <- format_data(d) \n\nrec <- build_recipe(d = d, config = best_config)\n\nrec_prepped <- rec |> \n  prep(training = d, strings_as_factors = FALSE)\n\nfeat_all <- rec_prepped |> \n  bake(new_data = d)\n\nmodel_best <- fit_best_model(best_model = best_config, \n                             feat = feat_all, \n                             ml_mode = \"classification\")\n```\n:::\n\n\n### SHAP for Feature Importance (using 1x 10-fold held-out folds)\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsplits <- d %>% \n  make_splits(cv_resample_type, cv_resample, cv_outer_resample, \n              cv_inner_resample, cv_group, seed_splits)\n\nall_shaps <- NULL\n\nsplit_nums <- 1:nrow(splits)\n\nfor (split_num in split_nums) {\n  \n  d_in <- training(splits$splits[[split_num]]) \n  d_out <- testing(splits$splits[[split_num]])\n  \n  rec <- build_recipe(d = d_in, config = best_config)\n  rec_prepped <- rec |> \n    prep(training = d_in, strings_as_factors = FALSE)\n  \n  feat_in <- rec_prepped |> \n    bake(new_data = NULL)\n  \n  model_best <- fit_best_model(best_config, feat = feat_in,\n                               \"classification\")\n  \n  feat_out <- rec_prepped |> \n    bake(new_data = d_out)\n  \n  # SHAP in held out fold\n  shaps_out <- SHAPforxgboost::shap.prep(\n    xgb_model = extract_fit_engine(model_best),\n    X_train = feat_out |> \n      select(-y) |>  \n      as.matrix()) |> \n    mutate(id_obs = rep(d_out$subid, times = ncol(feat_out) - 1),\n           split_num = split_num) |>  \n    relocate(id_obs, split_num)\n  \n  all_shaps <- all_shaps %>% \n    bind_rows(shaps_out)\n}\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n\nWarning in gower_work(x = x, y = y, pair_x = pair_x, pair_y = pair_y, n = n, :\nskipping variable with zero or non-finite range.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\ngrouped_shaps <- all_shaps |> \n  group_by(id_obs, variable) |> \n      summarize(value = mean(value), \n                # rfvalue is same across repeats but want included \n                rfvalue =  mean(rfvalue),  \n                mean_value = mean(mean_value))\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n`summarise()` has grouped output by 'id_obs'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\ngrouped_shaps %>% \n  group_by(variable) %>% \n  summarize(mean_value = mean(abs(value)), .groups = \"drop\") %>% \n  arrange(mean_value) %>% \n  mutate(variable = factor(variable),\n         variable = fct_inorder(variable)) %>% \n  slice_tail(n = 30) |> \n  ggplot(mapping = aes(x = variable, y = mean_value)) +\n  geom_point(size = 2, color = \"red\") +\n  geom_segment(aes(x = variable, y = mean_value, xend = variable), \n               yend = 0, colour = \"grey50\")  +\n  ylab(\"Mean |SHAP| value\") +\n  coord_flip()\n```\n\n::: {.cell-output-display}\n![](fit_final_model_26wk_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\ngrouped_shaps |> \n  group_by(variable) |> \n  summarize(mean_value = mean(abs(value)), .groups = \"drop\") |> \n  filter(str_detect(variable, \"treatment\")) |> \n  pull(mean_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\n[1] 0.0022278257 0.0041012774 0.0003676106\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nshap_rows <- grouped_shaps |> \n  group_by(variable) |> \n  summarize(mean_value = mean(abs(value)), .groups = \"drop\") |> \n  nrow()\n\ngrouped_shaps |> \n  group_by(variable) |> \n  summarize(mean_value = mean(abs(value)), .groups = \"drop\") |> \n  arrange(desc(mean_value)) |> \n  mutate(shap_rank = 1:shap_rows) |> \n  filter(str_detect(variable, \"treatment\")) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\nRows: 3\nColumns: 3\n$ variable   <fct> treatment_patch, treatment_combo_nrt, treatment_varenicline\n$ mean_value <dbl> 0.0041012774, 0.0022278257, 0.0003676106\n$ shap_rank  <int> 131, 189, 285\n```\n\n\n:::\n:::\n\n\n## Calculate and calibrate probabilities\n\nMake triplicate dataset\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nd_patch <- d |> \n  mutate(treatment = \"patch\") \n\nd_combo <- d |> \n  mutate(treatment = \"combo_nrt\")\n\nd_varen <- d |> \n  mutate(treatment = \"varenicline\")\n\nd_trip <- bind_rows(d_patch, d_combo) |> \n  bind_rows(d_varen) |> \n  mutate(treatment = factor(treatment, \n                            levels = c(\n                              \"patch\",\n                              \"varenicline\",\n                              \"combo_nrt\")))\n```\n:::\n\n\nBuild triplicate feature set\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nfeat_trip <- rec_prepped |> \n  bake(new_data = d_trip) \n```\n:::\n\n\nGet raw and calibrated probabilities\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\n# raw (uncalibrated) predictions for triplicated dataset\npreds_prob <- predict(model_best, feat_trip,\n                      type = \"prob\")\n\n# fit calibration model\nset.seed(2468)\ncal_split <- d |> \n  initial_split(prop = 3/4, strata = y)\nd_cal_in <- training(cal_split) \nd_cal_out <- testing(cal_split)\n\nrec_cal_prepped <- rec |> \n  prep(training = d_cal_in, strings_as_factors = FALSE)\n\nfeat_cal_in <- rec_cal_prepped |> \n  bake(new_data = NULL) \n\nfeat_cal_out <- rec_cal_prepped |> \n  bake(new_data = d_cal_out) \n\nmodel_cal <- fit_best_model(best_config, feat = feat_cal_in, \"classification\")\n\n# # beta calibration\n# beta <- predict(model_cal, feat_cal_out,\n#                 type = \"prob\") |>\n#   mutate(truth = feat_cal_out$y) |>\n#   cal_estimate_beta(truth = truth,\n#                     estimate = dplyr::starts_with(\".pred_\"),\n#                     smooth = TRUE)\n# preds_prob_beta <- preds_prob |>\n#   cal_apply(beta)\n# \n# # iso calibration\n# iso <- predict(model_cal, feat_cal_out,\n#                type = \"prob\") |>\n#   mutate(truth = feat_cal_out$y) |>\n#   cal_estimate_isotonic(truth = truth,\n#                         estimate = dplyr::starts_with(\".pred_\"))\n# preds_prob_iso <- preds_prob |>\n#   cal_apply(iso)\n# \n# # logistic calibration\n# logi <- predict(model_cal, feat_cal_out,\n#                 type = \"prob\") |>\n#   mutate(truth = feat_cal_out$y) |>\n#   cal_estimate_logistic(truth = truth,\n#                         estimate = dplyr::starts_with(\".pred_\"),\n#                         smooth = TRUE)\n# preds_prob_logi <- preds_prob |>\n#   cal_apply(logi)\n\n# combine raw and calibrated probs\nprobs <- tibble(subid = d_trip$subid,\n                tx = d_trip$treatment,\n                prob_raw = preds_prob[[str_c(\".pred_\", y_level_pos)]])\n#prob_beta = preds_prob_beta[[str_c(\".pred_\", y_level_pos)]],\n#prob_iso = preds_prob_iso[[str_c(\".pred_\", y_level_pos)]],\n#prob_logi = preds_prob_logi[[str_c(\".pred_\", y_level_pos)]]) \n\nglimpse(probs)\n```\n:::\n\n\n### Make AIM 2 Dataset\n\nPivot probabilities into wide format & select only raw probability (based on calibration validity check below)\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nraw_probs_wide <- probs |> \n  select(subid, tx, prob_raw) |> \n  pivot_wider(names_prefix = \"prob_\",\n              names_from = tx,\n              values_from = prob_raw)\n\nglimpse(raw_probs_wide)\n```\n:::\n\n\nJoin with d & create new variables\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nd_aim_2 <- d |> \n  select(subid, tx_rct = treatment, outcome_rct_wk4 = y) |> \n  left_join(raw_probs_wide, by = \"subid\") |> \n  mutate(tx_best = case_when(\n    prob_patch > prob_combo_nrt & prob_patch > prob_varenicline ~ \"patch\",\n    prob_combo_nrt > prob_patch & prob_combo_nrt > prob_varenicline ~ \"combo_nrt\",\n    prob_varenicline > prob_patch & prob_varenicline > prob_combo_nrt ~ \"varenicline\",\n    TRUE ~ NA_character_\n  )) |> \n  mutate(prob_best = case_when(\n    tx_best == \"patch\" ~ prob_patch,\n    tx_best == \"combo_nrt\" ~ prob_combo_nrt,\n    tx_best == \"varenicline\" ~ prob_varenicline,\n    TRUE ~ NA_real_\n  )) |> \n  mutate(tx_best = factor(tx_best, \n                          levels = c(\n                            \"patch\",\n                            \"varenicline\",\n                            \"combo_nrt\"))) |> \n  mutate(tx_match = if_else(tx_best == tx_rct, TRUE, FALSE)) |> \n  left_join(d_outcomes, by = \"subid\") |> \n  select(-pp_hybrid_wk4_outcome, -pp_hybrid_wk1_outcome, -pp_hybrid_yr3_outcome) |> # already in there from d\n  rename(outcome_rct_wk12 = pp_hybrid_wk12_outcome,\n         outcome_rct_wk26 = pp_hybrid_wk26_outcome,\n         outcome_rct_wk52 = pp_hybrid_wk52_outcome) |> \n  relocate(subid, tx_rct, tx_best, tx_match,\n           prob_best, starts_with(\"outcome\"), starts_with(\"prob\"))\n\nglimpse(d_aim_2)\n```\n:::\n\n\nQuick EDA checks\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\n# confirm logic worked as expected\nhead(d_aim_2)\n\n# check on variability of best tx\njanitor::tabyl(d_aim_2$tx_best)\n\n# check on variability of tx matching\njanitor::tabyl(d_aim_2$tx_match)\n\n# variability of matching within assignned (RCT) tx\nd_aim_2 |> \n  group_by(tx_rct) |> \n  tab(tx_match)\n```\n:::\n\n\nWrite out\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nd_aim_2 |> \n  write_csv(file.path(path_models, str_c(\"aim_2_\", version, \"_\", \n                                         y_col_name, \".csv\")))\n\nd_aim_2 |> \n  write_csv(here(\"/objects\", str_c(\"aim_2_\", version, \"_\", \n                                   y_col_name, \".csv\")))\n```\n:::\n\n\n### Validity check: Model Calibration\n\nMake wide format for all calibrated probabilities\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nall_probs_wide <- probs |> \n  rename_with(~ str_replace(.x, \"prob_\", \"\"), .cols = starts_with(\"prob_\")) |> \n  pivot_wider(\n    names_from = tx,\n    values_from = c(raw, beta, iso, logi),\n    names_glue = \"{.value}_{tx}\"\n  )\n```\n:::\n\n\nSet up validity check data\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nd_valid <- d_aim_2 |> \n  select(subid, tx_rct, outcome_rct_wk4) |> \n  left_join(all_probs_wide, by = \"subid\") |> \n  mutate(beta = case_when(\n    tx_rct == \"patch\" ~ beta_patch,\n    tx_rct == \"combo_nrt\" ~ beta_combo_nrt,\n    tx_rct == \"varenicline\" ~ beta_varenicline,\n    TRUE ~ NA_real_\n  ),\n  raw = case_when(\n    tx_rct == \"patch\" ~ raw_patch,\n    tx_rct == \"combo_nrt\" ~ raw_combo_nrt,\n    tx_rct == \"varenicline\" ~ raw_varenicline,\n    TRUE ~ NA_real_\n  ),\n  isotonic = case_when(\n    tx_rct == \"patch\" ~ iso_patch,\n    tx_rct == \"combo_nrt\" ~ iso_combo_nrt,\n    tx_rct == \"varenicline\" ~ iso_varenicline,\n    TRUE ~ NA_real_\n  ),\n  logistic = case_when(\n    tx_rct == \"patch\" ~ logi_patch,\n    tx_rct == \"combo_nrt\" ~ logi_combo_nrt,\n    tx_rct == \"varenicline\" ~ logi_varenicline,\n    TRUE ~ NA_real_\n  )) |> \n  select(subid, outcome_rct_wk4, beta, raw, isotonic, logistic) \n```\n:::\n\n\nCompare mean abstinence from RCT to predicted probabilities for RCT tx across calibrations\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nd_valid |> \n  mutate(outcome_rct = if_else(outcome_rct_wk4 == \"abstinent\", 1, 0)) |> \n  summarize(mean_rct = mean(outcome_rct_wk4),\n            mean_beta = mean(beta),\n            mean_iso = mean(isotonic),\n            mean_logi = mean(logistic),\n            mean_raw = mean(raw))\n```\n:::\n\nRaw probabilities appear to match the outcome best.\n\n#### Plots\n\nPivot data longer for required format\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nd_plot <- d_valid |> \n  pivot_longer(\n    cols = c(beta, raw, isotonic, logistic),\n    names_to = \"method\",\n    values_to = \".pred_abstinent\"\n  )\n```\n:::\n\n\nMake plots by calibration method\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nd_plot |> \n  cal_plot_breaks(truth = outcome_rct_wk4, \n                  estimate = .pred_abstinent,\n                  .by = method)\n\nd_plot |> \n  cal_plot_windowed(truth = outcome_rct_wk4, \n                    estimate = .pred_abstinent,\n                    .by = method)\n```\n:::\n\n\nRaw probabilities appear the most well-calibrated: best aligned with diagonal line, spans the fullest range of bins/windows. Will use raw probabilities for AIM 2 analyses (selected above).",
    "supporting": [
      "fit_final_model_26wk_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}